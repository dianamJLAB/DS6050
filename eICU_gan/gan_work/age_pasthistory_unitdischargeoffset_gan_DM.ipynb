{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c_5e8_VcuC7r"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, LeakyReLU, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K0Kj1O1juC7u"
      },
      "outputs": [],
      "source": [
        "class ConditionalGAN(keras.Model):\n",
        "    def __init__(self, noise_dim=50, \n",
        "                 data_shape=1,\n",
        "                 num_classes=3, \n",
        "                 d_learning_rate=1e-5, \n",
        "                 g_learning_rate=1e-6, \n",
        "                 batch_size=64, \n",
        "                 start_epoch=0,\n",
        "                 verbose = False):\n",
        "\n",
        "        super(ConditionalGAN, self).__init__()\n",
        "        self.noise_dim = noise_dim\n",
        "        self.data_shape = data_shape # output shape of the generator and goes to discriminator\n",
        "        self.num_classes = num_classes\n",
        "        self.d_optimizer = tf.keras.optimizers.Adam(d_learning_rate)\n",
        "        self.g_optimizer = tf.keras.optimizers.Adam(g_learning_rate)\n",
        "        self.batch_size = batch_size\n",
        "        self.start_epoch = start_epoch\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
        "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "\n",
        "        # add number of class labels to the input channels for generator\n",
        "        self.g_dim = self.noise_dim + self.num_classes\n",
        "\n",
        "        # add the number of class labels to the input to the discriminator\n",
        "        self.d_dim = self.data_shape + self.num_classes\n",
        "\n",
        "        if (self.verbose):\n",
        "            print(\"Generator input dim: \", self.g_dim)\n",
        "            print(\"Dicrimination input dim: \", self.d_dim)\n",
        "\n",
        "\n",
        "        # build generator and discriminator\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
        "    \n",
        "    def build_generator(self):\n",
        "        \"Build the generator model\"\n",
        "        inputs = Input(shape=(self.g_dim,))\n",
        "        hidden = Dense(64)(inputs) # 128\n",
        "        hidden = LeakyReLU(alpha=0.2)(hidden)\n",
        "        hidden = BatchNormalization()(hidden)\n",
        "        hidden = Dense(64)(hidden)\n",
        "        hidden = LeakyReLU(alpha=0.2)(hidden)\n",
        "\n",
        "        output = Dense(self.data_shape, activation=\"sigmoid\")(hidden)\n",
        "        #output = Dense(self.data_shape, activation=\"linear\")(hidden)\n",
        "\n",
        "        generator = Model(inputs=inputs, outputs=output, name=\"generator\")\n",
        "        generator.summary()\n",
        "        return generator\n",
        "\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        \"build the discriminator model\"\n",
        "        d_inputs = Input(shape=(self.d_dim,))\n",
        "        h = Dense(64, input_shape=(self.g_dim,))(d_inputs) \n",
        "        h = LeakyReLU(alpha=0.2)(h)\n",
        "        h = Dropout(0.1)(h)\n",
        "        h = Dense(64)(h) #32\n",
        "        h = LeakyReLU(alpha=0.2)(h)\n",
        "        h = Dropout(0.1)(h)\n",
        "        h = Dense(1, activation=\"sigmoid\")(h)\n",
        "        discriminator = Model(d_inputs, h, name=\"discriminator\")\n",
        "        discriminator.summary()\n",
        "        return discriminator\n",
        "\n",
        "    def compile(self, loss_fn):\n",
        "        super(ConditionalGAN, self).compile()\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data.\n",
        "        real_ages, one_hot_labels = data\n",
        "        real_ages = tf.cast(real_ages, tf.float32)\n",
        "        #print(\"real_ages:\", real_ages[0:2])\n",
        "\n",
        "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
        "        # the images. This is for the discriminator.\n",
        "        age_one_hot_labels = one_hot_labels[:, None]\n",
        "        print(\"age_one_hot_labels1:\", age_one_hot_labels[0:2])\n",
        "\n",
        "        age_one_hot_labels = tf.repeat(age_one_hot_labels, repeats=[1])\n",
        "        print(\"age_one_hot_labels2:\", age_one_hot_labels[0:2])\n",
        "\n",
        "        age_one_hot_labels = tf.reshape(age_one_hot_labels, (-1, self.num_classes))\n",
        "        age_one_hot_labels = tf.cast(age_one_hot_labels, tf.float32)\n",
        "        print(\"age_one_hot_labels3:\", age_one_hot_labels[0:2])\n",
        "\n",
        "        # Sample random points in the latent space and concatenate the labels.\n",
        "        # This is for the generator.\n",
        "        batch_size = tf.shape(real_ages)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.noise_dim))\n",
        "        random_vector_labels = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
        "\n",
        "        # Decode the noise (guided by labels) to fake ages.\n",
        "        generated_ages = self.generator(random_vector_labels)\n",
        "        generated_ages= tf.cast(generated_ages, tf.float32)\n",
        "\n",
        "        # Combine them with real images. Note that we are concatenating the labels\n",
        "        # with these images here. and tf.concat is on the last dimension (-1)\n",
        "        fake_ages_and_labels = tf.concat([generated_ages, age_one_hot_labels], -1)\n",
        "        real_ages_and_labels = tf.concat([real_ages, age_one_hot_labels], -1) \n",
        "        combined_ages = tf.concat([fake_ages_and_labels, real_ages_and_labels], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake ages. 1 == fake, 0 == real\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "\n",
        "        # TODO: concerned that observations are ordered fake then real - do we want to concat, then shuffle, then separate?\n",
        "        \n",
        "        #labels = tf.random.shuffle(labels, seed = 24)\n",
        "\n",
        "        # Train the discriminator.\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_ages)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space.t\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.noise_dim))\n",
        "        random_vector_labels = tf.concat(\n",
        "            [random_latent_vectors, one_hot_labels], axis=1\n",
        "        )\n",
        "\n",
        "        # Assemble labels that say \"all real images\".\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_ages = self.generator(random_vector_labels)\n",
        "            fake_ages_and_labels = tf.concat([fake_ages, age_one_hot_labels], -1)\n",
        "            predictions = self.discriminator(fake_ages_and_labels)\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Monitor loss.\n",
        "        self.gen_loss_tracker.update_state(g_loss)\n",
        "        self.disc_loss_tracker.update_state(d_loss)\n",
        "        return {\n",
        "            \"g_loss\": self.gen_loss_tracker.result(),\n",
        "            \"d_loss\": self.disc_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "    def generate(self, n=1000, one_hot_label=[1., 0., 0.]):\n",
        "        \"\"\"Generate n ages for a class\"\"\"\n",
        "        print(\"Generating: \", n, \" ages for unit type: \", one_hot_label)\n",
        "        input_noise = tf.random.normal((n, self.noise_dim), 0, 1)\n",
        "        random_vector_labels = tf.concat([input_noise, one_hot_label], axis=1)\n",
        "\n",
        "        ages = self.generator(random_vector_labels)\n",
        "\n",
        "        return ages.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4wxEV4vouC7x"
      },
      "outputs": [],
      "source": [
        "ages_ph_lenth_np = np.load(\"..\\data\\data_age_unitdischargeoffset_pasthistories.csv.npy\", allow_pickle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZmKz22HuC7y",
        "outputId": "81b583ae-35bc-40a3-94b6-9927fb830670"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[(87,), ('Caucasian',)],\n",
              "       [(87,), ('Caucasian',)],\n",
              "       [(76,), ('Caucasian',)],\n",
              "       ...,\n",
              "       [(41,), ('African American',)],\n",
              "       [(72,), ('Caucasian',)],\n",
              "       [(50,), ('Caucasian',)]], dtype=object)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ages_ethnicity_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIWt5ZbvuC7y",
        "outputId": "0651bde7-1df6-40e9-a85e-86b9557c0f65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ethnicity length:  2253\n"
          ]
        }
      ],
      "source": [
        "ethnicity_np = np.asarray(ages_ethnicity_np[:,1].flatten().tolist()).flatten()\n",
        "print('ethnicity length: ', len(ethnicity_np))\n",
        "#print(ethnicity_np[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhTefOGQuC7y",
        "outputId": "035a4e1b-5f29-4b99-9cad-7c67048205db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length:  2253\n",
            "[[(87,) ('Caucasian',)]\n",
            " [(87,) ('Caucasian',)]\n",
            " [(76,) ('Caucasian',)]\n",
            " [(34,) ('Caucasian',)]\n",
            " [(61,) ('Caucasian',)]]\n",
            "ages length:  2253\n",
            "ethnicity length:  2253\n",
            "(2253, 2)\n",
            "                   age\n",
            "ethnicity             \n",
            "African American   231\n",
            "Caucasian         2010\n",
            "Native American     12\n",
            "============================================================\n",
            "FILTERED:\n",
            "                   age  ethnicity_code\n",
            "ethnicity                             \n",
            "African American   230             230\n",
            "Caucasian         2010            2010\n",
            "Native American     12              12\n",
            "mean age:  63.507548845470694\n",
            "std age:  17.573\n",
            "min age:  15\n",
            "max age:  89\n",
            "[0.972972972972973, 0.972972972972973, 0.8243243243243243, 0.25675675675675674, 0.6216216216216216]\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n",
            "Shape of ages: (2252, 1)\n",
            "Shape of labels: (2252, 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "ages_ethnicity_np = np.load(\"/content/drive/MyDrive/DS6050-main/eICU_gan/data/eICU_age_ethnicity.npy\", allow_pickle=True)\n",
        "print('length: ', len(ages_ethnicity_np))\n",
        "print(ages_ethnicity_np[0:5])\n",
        "\n",
        "ages_np = np.asarray(ages_ethnicity_np[:,0].flatten().tolist()).flatten()\n",
        "print('ages length: ', len(ages_np))\n",
        "#print(ages_np[0:5])\n",
        "\n",
        "ethnicity_np = np.asarray(ages_ethnicity_np[:,1].flatten().tolist()).flatten()\n",
        "print('ethnicity length: ', len(ethnicity_np))\n",
        "#print(ethnicity_np[0:5])\n",
        "\n",
        "df_ages = pd.DataFrame(zip(ages_np, ethnicity_np), columns=['age','ethnicity'])\n",
        "print(df_ages.shape)\n",
        "print(df_ages.groupby('ethnicity').count())\n",
        "\n",
        "# create data set without 90 or greater since that was a category flattened\n",
        "print(\"==\" * 30)\n",
        "print(\"FILTERED:\")\n",
        "df_ages_filtered = df_ages.query(\"age < 90\")\n",
        "df_ages_filtered['ethnicity_code'] = df_ages_filtered['ethnicity'].astype('category').cat.codes\n",
        "print(df_ages_filtered.groupby('ethnicity').count())\n",
        "\n",
        "\n",
        "mean_age_filtered = df_ages_filtered.age.mean()\n",
        "std_age_filtered =  df_ages_filtered.age.std()\n",
        "min_age_filtered =  df_ages_filtered.age.min()\n",
        "max_age_filtered =  df_ages_filtered.age.max()\n",
        "\n",
        "print(\"mean age: \", mean_age_filtered)\n",
        "print(\"std age: \", np.round(std_age_filtered,3))\n",
        "print(\"min age: \", min_age_filtered)\n",
        "print(\"max age: \", max_age_filtered)\n",
        "\n",
        "scaled_ages_filtered = [(x - min_age_filtered)/(max_age_filtered - min_age_filtered) for x in df_ages_filtered['age']]\n",
        "all_ages = np.reshape(scaled_ages_filtered, (-1, 1))\n",
        "\n",
        "all_labels = keras.utils.to_categorical(df_ages_filtered['ethnicity_code'], 3)\n",
        "\n",
        "\n",
        "print(scaled_ages_filtered[0:5])\n",
        "print(np.array(all_labels[0:5]))\n",
        "print(f\"Shape of ages: {all_ages.shape}\")\n",
        "\n",
        "print(f\"Shape of labels: {all_labels.shape}\")\n",
        "\n",
        "# Create tf.data.Dataset.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((all_ages, all_labels))\n",
        "dataset = dataset.shuffle(buffer_size=200).batch(64)\n",
        "#list(dataset.as_numpy_iterator())\n",
        "#for element in dataset:\n",
        "#    print(element)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "RJ80Cu_fuC7z",
        "outputId": "b58016d4-4523-43db-bea9-abb3ac131052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.histplot(data=df_ages, x='age', hue='ethnicity', bins=70, color='orange', kde=True, alpha=0.6)\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GWKp3RHXuC7z",
        "outputId": "f76b31d7-e30c-44fb-b8a9-03dd0e22f324"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e084ca16-b219-4d30-9f03-818f19f724c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>African American</th>\n",
              "      <th>Caucasian</th>\n",
              "      <th>Native American</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>62</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>41</td>\n",
              "      <td>African American</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2250</th>\n",
              "      <td>41</td>\n",
              "      <td>African American</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2251</th>\n",
              "      <td>72</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2252</th>\n",
              "      <td>50</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e084ca16-b219-4d30-9f03-818f19f724c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e084ca16-b219-4d30-9f03-818f19f724c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e084ca16-b219-4d30-9f03-818f19f724c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      age         ethnicity  African American  Caucasian  Native American\n",
              "2248   62         Caucasian               0.0        1.0              0.0\n",
              "2249   41  African American               1.0        0.0              0.0\n",
              "2250   41  African American               1.0        0.0              0.0\n",
              "2251   72         Caucasian               0.0        1.0              0.0\n",
              "2252   50         Caucasian               0.0        1.0              0.0"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# one hot encode the ethnicity\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "encoder_df = pd.DataFrame(encoder.fit_transform(df_ages[['ethnicity']]).toarray())\n",
        "\n",
        "#merge one-hot encoded columns back with original DataFrame\n",
        "final_df = df_ages.join(encoder_df)\n",
        "final_df.columns = ['age', 'ethnicity', 'African American', 'Caucasian', 'Native American']\n",
        "final_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x4TWdUNGuC70",
        "outputId": "d3b181e7-4caf-4493-a9d6-9fb4bc004f0a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4da4e2cc-42bd-4a19-b231-ebe3a9a1c226\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">age</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ethnicity</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>African American</th>\n",
              "      <td>231.0</td>\n",
              "      <td>56.151515</td>\n",
              "      <td>16.861546</td>\n",
              "      <td>19.0</td>\n",
              "      <td>46.50</td>\n",
              "      <td>58.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Caucasian</th>\n",
              "      <td>2010.0</td>\n",
              "      <td>64.443781</td>\n",
              "      <td>17.419489</td>\n",
              "      <td>15.0</td>\n",
              "      <td>55.00</td>\n",
              "      <td>67.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>89.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Native American</th>\n",
              "      <td>12.0</td>\n",
              "      <td>50.500000</td>\n",
              "      <td>20.331346</td>\n",
              "      <td>19.0</td>\n",
              "      <td>39.25</td>\n",
              "      <td>48.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>88.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4da4e2cc-42bd-4a19-b231-ebe3a9a1c226')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4da4e2cc-42bd-4a19-b231-ebe3a9a1c226 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4da4e2cc-42bd-4a19-b231-ebe3a9a1c226');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     age                                                     \n",
              "                   count       mean        std   min    25%   50%   75%   max\n",
              "ethnicity                                                                    \n",
              "African American   231.0  56.151515  16.861546  19.0  46.50  58.0  69.0  90.0\n",
              "Caucasian         2010.0  64.443781  17.419489  15.0  55.00  67.0  78.0  89.0\n",
              "Native American     12.0  50.500000  20.331346  19.0  39.25  48.0  66.0  88.0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ages.groupby('ethnicity').describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7jflWgEuC70"
      },
      "source": [
        "## Plan\n",
        "1. Create the kde for each unit type (class)\n",
        "2. Sample from the kde on each training round per class\n",
        "    1. sample the same number of points as we have per class (e.g. 65 samples from the CSICU class)\n",
        "3. instead of training valid and fake spearately - intermingle and train together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYoRh28vuC71",
        "outputId": "ad8430ea-437c-46db-94c4-55749782a5f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator input dim:  53\n",
            "Dicrimination input dim:  4\n",
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 4)]               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                320       \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,545\n",
            "Trainable params: 4,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 53)]              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                3456      \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 64)                0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,937\n",
            "Trainable params: 7,809\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cgan = ConditionalGAN(noise_dim=50,\n",
        "                 data_shape=1,\n",
        "                 num_classes=3, \n",
        "                 d_learning_rate=1e-6, \n",
        "                 g_learning_rate=1e-6, \n",
        "                 batch_size=32, \n",
        "                 start_epoch=0,\n",
        "                 verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "g4SId-gauC72"
      },
      "outputs": [],
      "source": [
        "cgan.compile(loss_fn=keras.losses.BinaryCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO40wQe_uC72",
        "outputId": "a7c00142-3f00-4318-9dd4-9d60e89e58f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "age_one_hot_labels1: Tensor(\"strided_slice_1:0\", shape=(None, 1, 3), dtype=float32)\n",
            "age_one_hot_labels2: Tensor(\"strided_slice_2:0\", shape=(None,), dtype=float32)\n",
            "age_one_hot_labels3: Tensor(\"strided_slice_3:0\", shape=(None, 3), dtype=float32)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6935\n",
            "Epoch 7502/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6933\n",
            "Epoch 7503/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6933\n",
            "Epoch 7504/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6935\n",
            "Epoch 7505/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6934\n",
            "Epoch 7506/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6931\n",
            "Epoch 7507/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6933\n",
            "Epoch 7508/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6932\n",
            "Epoch 7509/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6933\n",
            "Epoch 7510/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 7511/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6933\n",
            "Epoch 7512/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6932\n",
            "Epoch 7513/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 7514/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 7515/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 7516/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 7517/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6933\n",
            "Epoch 7518/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6939 - d_loss: 0.6934\n",
            "Epoch 7519/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 7520/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7521/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6933\n",
            "Epoch 7522/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6935\n",
            "Epoch 7523/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6934\n",
            "Epoch 7524/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6934\n",
            "Epoch 7525/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 7526/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6933\n",
            "Epoch 7527/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 7528/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6935 - d_loss: 0.6935\n",
            "Epoch 7529/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6935\n",
            "Epoch 7530/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6934\n",
            "Epoch 7531/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 7532/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 7533/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6933\n",
            "Epoch 7534/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6931\n",
            "Epoch 7535/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6933\n",
            "Epoch 7536/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6935\n",
            "Epoch 7537/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6931\n",
            "Epoch 7538/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 7539/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6937 - d_loss: 0.6934\n",
            "Epoch 7540/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 7541/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 7542/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 7543/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6933\n",
            "Epoch 7544/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6934\n",
            "Epoch 7545/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6930\n",
            "Epoch 7546/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 7547/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 7548/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 7549/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 7550/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 7551/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 7552/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 7553/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 7554/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6935\n",
            "Epoch 7555/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6934\n",
            "Epoch 7556/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 7557/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 7558/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7559/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 7560/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 7561/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 7562/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7563/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 7564/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 7565/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 7566/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 7567/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 7568/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 7569/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 7570/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 7571/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 7572/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 7573/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 7574/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6933\n",
            "Epoch 7575/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 7576/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7577/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 7578/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 7579/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 7580/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 7581/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 7582/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 7583/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 7584/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6930\n",
            "Epoch 7585/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6931\n",
            "Epoch 7586/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 7587/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 7588/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 7589/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7590/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7591/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 7592/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 7593/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7594/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 7595/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7596/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 7597/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 7598/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 7599/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 7600/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 7601/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6930\n",
            "Epoch 7602/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 7603/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 7604/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 7605/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 7606/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7607/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 7608/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 7609/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 7610/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 7611/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 7612/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 7613/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6930\n",
            "Epoch 7614/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 7615/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 7616/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 7617/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 7618/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 7619/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6933\n",
            "Epoch 7620/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6930\n",
            "Epoch 7621/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 7622/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 7623/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 7624/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7625/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 7626/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 7627/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 7628/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 7629/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6929\n",
            "Epoch 7630/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6931\n",
            "Epoch 7631/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 7632/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 7633/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 7634/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 7635/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 7636/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 7637/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 7638/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 7639/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 7640/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 7641/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 7642/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7643/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 7644/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 7645/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 7646/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 7647/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 7648/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 7649/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 7650/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 7651/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6931\n",
            "Epoch 7652/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 7653/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 7654/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 7655/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 7656/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 7657/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 7658/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 7659/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 7660/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 7661/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 7662/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 7663/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 7664/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 7665/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 7666/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 7667/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6931\n",
            "Epoch 7668/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 7669/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6930\n",
            "Epoch 7670/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 7671/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 7672/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 7673/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 7674/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 7675/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 7676/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6930\n",
            "Epoch 7677/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 7678/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 7679/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 7680/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6930\n",
            "Epoch 7681/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 7682/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 7683/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 7684/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6931\n",
            "Epoch 7685/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 7686/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 7687/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6930\n",
            "Epoch 7688/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 7689/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 7690/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6930\n",
            "Epoch 7691/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6929\n",
            "Epoch 7692/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6930\n",
            "Epoch 7693/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 7694/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 7695/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6929\n",
            "Epoch 7696/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 7697/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 7698/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 7699/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6930\n",
            "Epoch 7700/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6929\n",
            "Epoch 7701/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6929\n",
            "Epoch 7702/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 7703/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 7704/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 7705/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 7706/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7707/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 7708/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 7709/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7710/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 7711/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6928\n",
            "Epoch 7712/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 7713/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7714/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6925\n",
            "Epoch 7715/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 7716/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 7717/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 7718/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7719/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7720/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6930\n",
            "Epoch 7721/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 7722/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7723/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 7724/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 7725/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6928\n",
            "Epoch 7726/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 7727/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 7728/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 7729/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 7730/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6929\n",
            "Epoch 7731/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 7732/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6941 - d_loss: 0.6927\n",
            "Epoch 7733/10000\n",
            "36/36 [==============================] - 0s 7ms/step - g_loss: 0.6941 - d_loss: 0.6929\n",
            "Epoch 7734/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6929\n",
            "Epoch 7735/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 7736/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6929\n",
            "Epoch 7737/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 7738/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 7739/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6928\n",
            "Epoch 7740/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 7741/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 7742/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 7743/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7744/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 7745/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7746/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 7747/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 7748/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 7749/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 7750/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7751/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 7752/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 7753/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 7754/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 7755/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7756/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 7757/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 7758/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6926\n",
            "Epoch 7759/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7760/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6929\n",
            "Epoch 7761/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 7762/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7763/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 7764/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7765/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 7766/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 7767/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7768/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 7769/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7770/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 7771/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 7772/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6929\n",
            "Epoch 7773/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7774/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 7775/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 7776/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6927\n",
            "Epoch 7777/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 7778/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6925\n",
            "Epoch 7779/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 7780/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 7781/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 7782/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6926\n",
            "Epoch 7783/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7784/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 7785/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6930\n",
            "Epoch 7786/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 7787/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7788/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 7789/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 7790/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7791/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7792/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 7793/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 7794/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7795/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 7796/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7797/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 7798/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 7799/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 7800/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6926\n",
            "Epoch 7801/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 7802/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7803/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 7804/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 7805/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 7806/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 7807/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 7808/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 7809/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 7810/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7811/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7812/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7813/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 7814/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 7815/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7816/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 7817/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 7818/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7819/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7820/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7821/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7822/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7823/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6925\n",
            "Epoch 7824/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 7825/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6926\n",
            "Epoch 7826/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 7827/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6934 - d_loss: 0.6925\n",
            "Epoch 7828/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 7829/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6926\n",
            "Epoch 7830/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6925\n",
            "Epoch 7831/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 7832/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 7833/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6925\n",
            "Epoch 7834/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 7835/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6924\n",
            "Epoch 7836/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7837/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 7838/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 7839/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6925\n",
            "Epoch 7840/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 7841/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 7842/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 7843/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6929\n",
            "Epoch 7844/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 7845/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6925\n",
            "Epoch 7846/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7847/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7848/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 7849/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6926\n",
            "Epoch 7850/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6934 - d_loss: 0.6924\n",
            "Epoch 7851/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6925\n",
            "Epoch 7852/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6927\n",
            "Epoch 7853/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 7854/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 7855/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7856/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7857/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 7858/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 7859/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 7860/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 7861/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 7862/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7863/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7864/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 7865/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7866/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7867/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7868/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7869/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6924\n",
            "Epoch 7870/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6925\n",
            "Epoch 7871/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7872/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7873/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 7874/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 7875/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 7876/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 7877/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 7878/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 7879/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 7880/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6928\n",
            "Epoch 7881/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 7882/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7883/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 7884/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 7885/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 7886/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 7887/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6925\n",
            "Epoch 7888/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 7889/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6925\n",
            "Epoch 7890/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 7891/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7892/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 7893/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 7894/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 7895/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 7896/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6943 - d_loss: 0.6927\n",
            "Epoch 7897/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6944 - d_loss: 0.6926\n",
            "Epoch 7898/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6928\n",
            "Epoch 7899/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 7900/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6929\n",
            "Epoch 7901/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6929\n",
            "Epoch 7902/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 7903/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6925\n",
            "Epoch 7904/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7905/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 7906/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 7907/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 7908/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 7909/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 7910/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 7911/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6928\n",
            "Epoch 7912/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6945 - d_loss: 0.6924\n",
            "Epoch 7913/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6925\n",
            "Epoch 7914/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 7915/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 7916/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6928\n",
            "Epoch 7917/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7918/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7919/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7920/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6925\n",
            "Epoch 7921/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6926\n",
            "Epoch 7922/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7923/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 7924/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6926\n",
            "Epoch 7925/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6944 - d_loss: 0.6927\n",
            "Epoch 7926/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6925\n",
            "Epoch 7927/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 7928/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 7929/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 7930/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6944 - d_loss: 0.6927\n",
            "Epoch 7931/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6926\n",
            "Epoch 7932/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6946 - d_loss: 0.6928\n",
            "Epoch 7933/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 7934/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 7935/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 7936/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 7937/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7938/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 7939/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6944 - d_loss: 0.6926\n",
            "Epoch 7940/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6927\n",
            "Epoch 7941/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 7942/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6925\n",
            "Epoch 7943/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 7944/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7945/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 7946/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7947/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7948/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7949/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6929\n",
            "Epoch 7950/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7951/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 7952/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7953/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6927\n",
            "Epoch 7954/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6926\n",
            "Epoch 7955/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 7956/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 7957/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6944 - d_loss: 0.6927\n",
            "Epoch 7958/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 7959/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 7960/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6925\n",
            "Epoch 7961/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 7962/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 7963/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 7964/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6926\n",
            "Epoch 7965/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 7966/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 7967/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6944 - d_loss: 0.6926\n",
            "Epoch 7968/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 7969/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 7970/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6927\n",
            "Epoch 7971/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6927\n",
            "Epoch 7972/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 7973/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 7974/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 7975/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6944 - d_loss: 0.6927\n",
            "Epoch 7976/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 7977/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7978/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 7979/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 7980/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 7981/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7982/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 7983/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 7984/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 7985/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 7986/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 7987/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 7988/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7989/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6926\n",
            "Epoch 7990/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 7991/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 7992/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7993/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 7994/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 7995/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6928\n",
            "Epoch 7996/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6924\n",
            "Epoch 7997/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 7998/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 7999/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 8000/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8001/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8002/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 8003/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8004/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8005/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 8006/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 8007/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6930 - d_loss: 0.6926\n",
            "Epoch 8008/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6928\n",
            "Epoch 8009/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 8010/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8011/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 8012/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 8013/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 8014/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 8015/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8016/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 8017/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8018/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 8019/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 8020/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8021/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 8022/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6927\n",
            "Epoch 8023/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6926\n",
            "Epoch 8024/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 8025/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6927\n",
            "Epoch 8026/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 8027/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 8028/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 8029/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8030/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6928\n",
            "Epoch 8031/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8032/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 8033/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6927\n",
            "Epoch 8034/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 8035/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8036/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 8037/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8038/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8039/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 8040/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8041/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 8042/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8043/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8044/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6927\n",
            "Epoch 8045/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 8046/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 8047/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6927\n",
            "Epoch 8048/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 8049/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8050/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8051/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8052/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 8053/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8054/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 8055/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 8056/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 8057/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 8058/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 8059/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 8060/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8061/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6929 - d_loss: 0.6927\n",
            "Epoch 8062/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6927\n",
            "Epoch 8063/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 8064/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8065/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 8066/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 8067/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8068/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8069/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 8070/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 8071/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8072/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8073/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 8074/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 8075/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8076/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8077/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 8078/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8079/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8080/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8081/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8082/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 8083/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 8084/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 8085/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8086/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8087/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 8088/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8089/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 8090/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8091/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 8092/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 8093/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 8094/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 8095/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 8096/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8097/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 8098/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8099/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8100/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 8101/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 8102/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 8103/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 8104/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8105/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8106/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6931\n",
            "Epoch 8107/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6929\n",
            "Epoch 8108/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6930\n",
            "Epoch 8109/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 8110/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 8111/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 8112/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8113/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 8114/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8115/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 8116/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 8117/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 8118/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8119/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 8120/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8121/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8122/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 8123/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 8124/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8125/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8126/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8127/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 8128/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6930\n",
            "Epoch 8129/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8130/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 8131/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 8132/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 8133/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 8134/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 8135/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 8136/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8137/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 8138/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 8139/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8140/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 8141/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8142/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 8143/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 8144/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 8145/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 8146/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8147/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 8148/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8149/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 8150/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 8151/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8152/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 8153/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8154/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8155/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 8156/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 8157/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 8158/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 8159/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 8160/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8161/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8162/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 8163/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 8164/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 8165/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8166/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8167/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8168/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 8169/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8170/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8171/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 8172/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8173/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6930\n",
            "Epoch 8174/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8175/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8176/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6930\n",
            "Epoch 8177/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8178/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8179/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 8180/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6930\n",
            "Epoch 8181/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 8182/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8183/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8184/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 8185/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8186/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8187/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8188/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8189/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8190/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8191/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 8192/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8193/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6929\n",
            "Epoch 8194/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8195/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8196/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 8197/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 8198/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8199/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6928 - d_loss: 0.6930\n",
            "Epoch 8200/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6930\n",
            "Epoch 8201/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 8202/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8203/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8204/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 8205/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 8206/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8207/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8208/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 8209/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8210/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8211/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6930\n",
            "Epoch 8212/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8213/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8214/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 8215/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8216/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8217/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 8218/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 8219/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8220/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8221/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8222/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8223/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8224/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8225/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8226/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8227/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8228/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6931\n",
            "Epoch 8229/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6930\n",
            "Epoch 8230/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8231/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6931\n",
            "Epoch 8232/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8233/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8234/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8235/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 8236/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 8237/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 8238/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8239/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8240/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 8241/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8242/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 8243/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6930\n",
            "Epoch 8244/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 8245/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8246/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8247/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8248/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8249/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 8250/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8251/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8252/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 8253/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 8254/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 8255/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8256/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6933\n",
            "Epoch 8257/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8258/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8259/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8260/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6927 - d_loss: 0.6933\n",
            "Epoch 8261/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6931\n",
            "Epoch 8262/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8263/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8264/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8265/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8266/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8267/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8268/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6932\n",
            "Epoch 8269/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 8270/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6932\n",
            "Epoch 8271/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6931\n",
            "Epoch 8272/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8273/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8274/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8275/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8276/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8277/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 8278/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8279/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8280/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6934\n",
            "Epoch 8281/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8282/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8283/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6930\n",
            "Epoch 8284/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6925 - d_loss: 0.6932\n",
            "Epoch 8285/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8286/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6932\n",
            "Epoch 8287/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6932\n",
            "Epoch 8288/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8289/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6934\n",
            "Epoch 8290/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8291/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8292/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6933\n",
            "Epoch 8293/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8294/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8295/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8296/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 8297/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8298/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 8299/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8300/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8301/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8302/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 8303/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8304/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 8305/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8306/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8307/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 8308/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8309/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8310/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6934\n",
            "Epoch 8311/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8312/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 8313/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 8314/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8315/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8316/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8317/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8318/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8319/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 8320/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 8321/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 8322/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 8323/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 8324/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 8325/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8326/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8327/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8328/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8329/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6934\n",
            "Epoch 8330/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8331/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 8332/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 8333/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6932\n",
            "Epoch 8334/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8335/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8336/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8337/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8338/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8339/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8340/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8341/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8342/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 8343/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6932\n",
            "Epoch 8344/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 8345/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8346/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8347/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8348/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6933\n",
            "Epoch 8349/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8350/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6933\n",
            "Epoch 8351/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8352/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6933\n",
            "Epoch 8353/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8354/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8355/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8356/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 8357/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8358/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8359/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6926 - d_loss: 0.6932\n",
            "Epoch 8360/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 8361/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 8362/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 8363/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8364/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6935\n",
            "Epoch 8365/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8366/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 8367/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8368/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6934\n",
            "Epoch 8369/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8370/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8371/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8372/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8373/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8374/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 8375/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6934\n",
            "Epoch 8376/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8377/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8378/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8379/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8380/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8381/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8382/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6934\n",
            "Epoch 8383/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 8384/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 8385/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8386/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 8387/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 8388/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8389/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8390/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8391/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8392/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8393/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6932\n",
            "Epoch 8394/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8395/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8396/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8397/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8398/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8399/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8400/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 8401/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8402/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6935\n",
            "Epoch 8403/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8404/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6933\n",
            "Epoch 8405/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8406/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 8407/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8408/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8409/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8410/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8411/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8412/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6930\n",
            "Epoch 8413/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8414/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8415/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6932\n",
            "Epoch 8416/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8417/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8418/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 8419/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8420/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8421/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8422/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 8423/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 8424/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 8425/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8426/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 8427/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8428/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8429/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8430/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 8431/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8432/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8433/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8434/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8435/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8436/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8437/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8438/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8439/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8440/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8441/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 8442/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8443/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8444/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8445/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8446/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 8447/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8448/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6929 - d_loss: 0.6931\n",
            "Epoch 8449/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8450/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8451/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8452/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8453/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8454/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 8455/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8456/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 8457/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8458/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8459/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 8460/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 8461/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8462/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8463/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 8464/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8465/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8466/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8467/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 8468/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 8469/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8470/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8471/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8472/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8473/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8474/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8475/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8476/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6929 - d_loss: 0.6931\n",
            "Epoch 8477/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 8478/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6930\n",
            "Epoch 8479/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8480/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8481/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 8482/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8483/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 8484/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 8485/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8486/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6931\n",
            "Epoch 8487/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 8488/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 8489/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 8490/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8491/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8492/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8493/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 8494/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8495/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 8496/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8497/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8498/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 8499/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8500/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 8501/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8502/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8503/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8504/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 8505/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8506/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8507/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8508/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8509/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8510/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8511/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8512/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8513/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 8514/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8515/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 8516/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 8517/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8518/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 8519/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8520/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 8521/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 8522/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8523/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 8524/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 8525/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 8526/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 8527/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8528/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8529/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 8530/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 8531/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 8532/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 8533/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 8534/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 8535/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 8536/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 8537/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 8538/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8539/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 8540/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 8541/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 8542/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 8543/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 8544/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 8545/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8546/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 8547/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 8548/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 8549/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8550/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8551/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8552/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8553/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8554/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 8555/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 8556/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8557/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8558/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8559/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8560/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 8561/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 8562/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8563/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8564/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 8565/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 8566/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8567/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8568/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8569/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 8570/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8571/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8572/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6926\n",
            "Epoch 8573/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8574/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 8575/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 8576/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8577/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 8578/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8579/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6926\n",
            "Epoch 8580/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6926\n",
            "Epoch 8581/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 8582/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8583/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 8584/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8585/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 8586/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 8587/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6926\n",
            "Epoch 8588/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 8589/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 8590/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 8591/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6926\n",
            "Epoch 8592/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6926\n",
            "Epoch 8593/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 8594/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 8595/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 8596/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 8597/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 8598/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 8599/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6925\n",
            "Epoch 8600/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 8601/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 8602/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6925\n",
            "Epoch 8603/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 8604/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 8605/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 8606/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6924\n",
            "Epoch 8607/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 8608/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 8609/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8610/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 8611/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 8612/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 8613/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 8614/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 8615/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 8616/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6925\n",
            "Epoch 8617/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6925\n",
            "Epoch 8618/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 8619/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 8620/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6924\n",
            "Epoch 8621/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 8622/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 8623/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6924\n",
            "Epoch 8624/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8625/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6924\n",
            "Epoch 8626/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6924\n",
            "Epoch 8627/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6924\n",
            "Epoch 8628/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6924\n",
            "Epoch 8629/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6924\n",
            "Epoch 8630/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6924\n",
            "Epoch 8631/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6924\n",
            "Epoch 8632/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6925\n",
            "Epoch 8633/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6924\n",
            "Epoch 8634/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6925\n",
            "Epoch 8635/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6923\n",
            "Epoch 8636/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6924\n",
            "Epoch 8637/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6923\n",
            "Epoch 8638/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6923\n",
            "Epoch 8639/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6924\n",
            "Epoch 8640/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6925\n",
            "Epoch 8641/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6924\n",
            "Epoch 8642/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6925\n",
            "Epoch 8643/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6923\n",
            "Epoch 8644/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6923\n",
            "Epoch 8645/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6925\n",
            "Epoch 8646/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6922\n",
            "Epoch 8647/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6923\n",
            "Epoch 8648/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6923\n",
            "Epoch 8649/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6923\n",
            "Epoch 8650/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8651/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6924\n",
            "Epoch 8652/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6922\n",
            "Epoch 8653/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6924\n",
            "Epoch 8654/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6922\n",
            "Epoch 8655/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6923\n",
            "Epoch 8656/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6922\n",
            "Epoch 8657/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6923\n",
            "Epoch 8658/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6922\n",
            "Epoch 8659/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8660/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6922\n",
            "Epoch 8661/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6922\n",
            "Epoch 8662/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6922\n",
            "Epoch 8663/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8664/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6923\n",
            "Epoch 8665/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8666/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6922\n",
            "Epoch 8667/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6922\n",
            "Epoch 8668/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6923\n",
            "Epoch 8669/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6922\n",
            "Epoch 8670/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6922\n",
            "Epoch 8671/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6922\n",
            "Epoch 8672/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8673/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6921\n",
            "Epoch 8674/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8675/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8676/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6923\n",
            "Epoch 8677/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6920\n",
            "Epoch 8678/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6921\n",
            "Epoch 8679/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6921\n",
            "Epoch 8680/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8681/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6920\n",
            "Epoch 8682/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6919\n",
            "Epoch 8683/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8684/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6921\n",
            "Epoch 8685/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6922\n",
            "Epoch 8686/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6921\n",
            "Epoch 8687/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6922\n",
            "Epoch 8688/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6921\n",
            "Epoch 8689/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6922\n",
            "Epoch 8690/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6922\n",
            "Epoch 8691/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8692/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6922\n",
            "Epoch 8693/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6922\n",
            "Epoch 8694/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6922\n",
            "Epoch 8695/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6920\n",
            "Epoch 8696/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6921\n",
            "Epoch 8697/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6920\n",
            "Epoch 8698/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6921\n",
            "Epoch 8699/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6921\n",
            "Epoch 8700/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6942 - d_loss: 0.6921\n",
            "Epoch 8701/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6922\n",
            "Epoch 8702/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6920\n",
            "Epoch 8703/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8704/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6921\n",
            "Epoch 8705/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6921\n",
            "Epoch 8706/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6921\n",
            "Epoch 8707/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6921\n",
            "Epoch 8708/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6920\n",
            "Epoch 8709/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6921\n",
            "Epoch 8710/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6920\n",
            "Epoch 8711/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8712/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6920\n",
            "Epoch 8713/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6919\n",
            "Epoch 8714/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6922\n",
            "Epoch 8715/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6919\n",
            "Epoch 8716/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8717/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6921\n",
            "Epoch 8718/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6922\n",
            "Epoch 8719/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6920\n",
            "Epoch 8720/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6920\n",
            "Epoch 8721/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6920\n",
            "Epoch 8722/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8723/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6921\n",
            "Epoch 8724/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6921\n",
            "Epoch 8725/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6921\n",
            "Epoch 8726/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6920\n",
            "Epoch 8727/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6920\n",
            "Epoch 8728/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6922\n",
            "Epoch 8729/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6920\n",
            "Epoch 8730/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6921\n",
            "Epoch 8731/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6920\n",
            "Epoch 8732/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8733/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8734/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6919\n",
            "Epoch 8735/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6920\n",
            "Epoch 8736/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6920\n",
            "Epoch 8737/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6923\n",
            "Epoch 8738/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6920\n",
            "Epoch 8739/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6918\n",
            "Epoch 8740/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6920\n",
            "Epoch 8741/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6920\n",
            "Epoch 8742/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6920\n",
            "Epoch 8743/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6921\n",
            "Epoch 8744/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6921\n",
            "Epoch 8745/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6921\n",
            "Epoch 8746/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6920\n",
            "Epoch 8747/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6919\n",
            "Epoch 8748/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6919\n",
            "Epoch 8749/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6920\n",
            "Epoch 8750/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6920\n",
            "Epoch 8751/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6922\n",
            "Epoch 8752/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6920\n",
            "Epoch 8753/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6921\n",
            "Epoch 8754/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6921\n",
            "Epoch 8755/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6921\n",
            "Epoch 8756/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6922\n",
            "Epoch 8757/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6921\n",
            "Epoch 8758/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6920\n",
            "Epoch 8759/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6921\n",
            "Epoch 8760/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6919\n",
            "Epoch 8761/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6920\n",
            "Epoch 8762/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6922\n",
            "Epoch 8763/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6921\n",
            "Epoch 8764/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6920\n",
            "Epoch 8765/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6921\n",
            "Epoch 8766/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6921\n",
            "Epoch 8767/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6921\n",
            "Epoch 8768/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6921\n",
            "Epoch 8769/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6920\n",
            "Epoch 8770/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6922\n",
            "Epoch 8771/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6920\n",
            "Epoch 8772/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6920\n",
            "Epoch 8773/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8774/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6920\n",
            "Epoch 8775/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6923\n",
            "Epoch 8776/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6921\n",
            "Epoch 8777/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6923\n",
            "Epoch 8778/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6921\n",
            "Epoch 8779/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6938 - d_loss: 0.6922\n",
            "Epoch 8780/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6923\n",
            "Epoch 8781/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6921\n",
            "Epoch 8782/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6920\n",
            "Epoch 8783/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6922\n",
            "Epoch 8784/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6921\n",
            "Epoch 8785/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6921\n",
            "Epoch 8786/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6921\n",
            "Epoch 8787/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6920\n",
            "Epoch 8788/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6922\n",
            "Epoch 8789/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8790/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6919\n",
            "Epoch 8791/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6922\n",
            "Epoch 8792/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6922\n",
            "Epoch 8793/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6922\n",
            "Epoch 8794/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6921\n",
            "Epoch 8795/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6921\n",
            "Epoch 8796/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6922\n",
            "Epoch 8797/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6922\n",
            "Epoch 8798/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6920\n",
            "Epoch 8799/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6921\n",
            "Epoch 8800/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6920\n",
            "Epoch 8801/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6923\n",
            "Epoch 8802/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6922\n",
            "Epoch 8803/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6923\n",
            "Epoch 8804/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8805/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6920\n",
            "Epoch 8806/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6922\n",
            "Epoch 8807/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6922\n",
            "Epoch 8808/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6923\n",
            "Epoch 8809/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6922\n",
            "Epoch 8810/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6921\n",
            "Epoch 8811/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6921\n",
            "Epoch 8812/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6922\n",
            "Epoch 8813/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6919\n",
            "Epoch 8814/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6922\n",
            "Epoch 8815/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8816/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6919\n",
            "Epoch 8817/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8818/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6923\n",
            "Epoch 8819/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6922\n",
            "Epoch 8820/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6921\n",
            "Epoch 8821/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6921\n",
            "Epoch 8822/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6922\n",
            "Epoch 8823/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6921\n",
            "Epoch 8824/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6923\n",
            "Epoch 8825/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6922\n",
            "Epoch 8826/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6924\n",
            "Epoch 8827/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8828/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6921\n",
            "Epoch 8829/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 8830/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6922\n",
            "Epoch 8831/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6923\n",
            "Epoch 8832/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8833/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6924\n",
            "Epoch 8834/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6923\n",
            "Epoch 8835/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6922\n",
            "Epoch 8836/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8837/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6921\n",
            "Epoch 8838/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8839/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6921\n",
            "Epoch 8840/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6922\n",
            "Epoch 8841/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6921\n",
            "Epoch 8842/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6922\n",
            "Epoch 8843/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6925\n",
            "Epoch 8844/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6923\n",
            "Epoch 8845/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6923\n",
            "Epoch 8846/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6923\n",
            "Epoch 8847/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6923\n",
            "Epoch 8848/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6923\n",
            "Epoch 8849/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6924\n",
            "Epoch 8850/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6924\n",
            "Epoch 8851/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6924\n",
            "Epoch 8852/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6923\n",
            "Epoch 8853/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6923\n",
            "Epoch 8854/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6923\n",
            "Epoch 8855/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6923\n",
            "Epoch 8856/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6922\n",
            "Epoch 8857/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6922\n",
            "Epoch 8858/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6924\n",
            "Epoch 8859/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8860/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6923\n",
            "Epoch 8861/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6925\n",
            "Epoch 8862/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6923\n",
            "Epoch 8863/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8864/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8865/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 8866/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6925\n",
            "Epoch 8867/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6923\n",
            "Epoch 8868/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6923\n",
            "Epoch 8869/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 8870/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6944 - d_loss: 0.6926\n",
            "Epoch 8871/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6925\n",
            "Epoch 8872/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6923\n",
            "Epoch 8873/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8874/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6922\n",
            "Epoch 8875/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6922\n",
            "Epoch 8876/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6925\n",
            "Epoch 8877/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6924\n",
            "Epoch 8878/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6925\n",
            "Epoch 8879/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6922\n",
            "Epoch 8880/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6924\n",
            "Epoch 8881/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6941 - d_loss: 0.6925\n",
            "Epoch 8882/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 8883/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6923\n",
            "Epoch 8884/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6937 - d_loss: 0.6925\n",
            "Epoch 8885/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 8886/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6928\n",
            "Epoch 8887/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6925\n",
            "Epoch 8888/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 8889/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 8890/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6924\n",
            "Epoch 8891/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 8892/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6923\n",
            "Epoch 8893/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6924\n",
            "Epoch 8894/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6923\n",
            "Epoch 8895/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 8896/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8897/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6923\n",
            "Epoch 8898/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 8899/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6924\n",
            "Epoch 8900/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6925\n",
            "Epoch 8901/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6924\n",
            "Epoch 8902/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 8903/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6925\n",
            "Epoch 8904/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 8905/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6924\n",
            "Epoch 8906/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 8907/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8908/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6924\n",
            "Epoch 8909/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8910/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 8911/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 8912/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6928\n",
            "Epoch 8913/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 8914/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 8915/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6924\n",
            "Epoch 8916/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 8917/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 8918/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 8919/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 8920/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 8921/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 8922/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 8923/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 8924/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6925\n",
            "Epoch 8925/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 8926/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6925\n",
            "Epoch 8927/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 8928/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 8929/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6923\n",
            "Epoch 8930/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 8931/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8932/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 8933/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 8934/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 8935/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 8936/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 8937/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 8938/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6923\n",
            "Epoch 8939/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6937 - d_loss: 0.6925\n",
            "Epoch 8940/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 8941/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 8942/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8943/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6925\n",
            "Epoch 8944/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 8945/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 8946/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 8947/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6925\n",
            "Epoch 8948/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 8949/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 8950/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 8951/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6926\n",
            "Epoch 8952/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 8953/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8954/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 8955/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 8956/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8957/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8958/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6927\n",
            "Epoch 8959/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 8960/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 8961/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6926\n",
            "Epoch 8962/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 8963/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6926\n",
            "Epoch 8964/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6929\n",
            "Epoch 8965/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 8966/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 8967/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 8968/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 8969/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6926\n",
            "Epoch 8970/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 8971/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 8972/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 8973/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6927\n",
            "Epoch 8974/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6928\n",
            "Epoch 8975/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6929\n",
            "Epoch 8976/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6929\n",
            "Epoch 8977/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6927\n",
            "Epoch 8978/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 8979/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6929\n",
            "Epoch 8980/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 8981/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6921 - d_loss: 0.6927\n",
            "Epoch 8982/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6926\n",
            "Epoch 8983/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6926\n",
            "Epoch 8984/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6928\n",
            "Epoch 8985/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6928\n",
            "Epoch 8986/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6927\n",
            "Epoch 8987/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 8988/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6928\n",
            "Epoch 8989/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6929\n",
            "Epoch 8990/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6929\n",
            "Epoch 8991/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6924 - d_loss: 0.6929\n",
            "Epoch 8992/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6923 - d_loss: 0.6931\n",
            "Epoch 8993/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6926 - d_loss: 0.6929\n",
            "Epoch 8994/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6927 - d_loss: 0.6930\n",
            "Epoch 8995/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6924 - d_loss: 0.6931\n",
            "Epoch 8996/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 8997/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6930\n",
            "Epoch 8998/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6928 - d_loss: 0.6930\n",
            "Epoch 8999/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6927 - d_loss: 0.6931\n",
            "Epoch 9000/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6923 - d_loss: 0.6930\n",
            "Epoch 9001/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6931\n",
            "Epoch 9002/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6921 - d_loss: 0.6930\n",
            "Epoch 9003/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6930\n",
            "Epoch 9004/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6929\n",
            "Epoch 9005/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6924 - d_loss: 0.6928\n",
            "Epoch 9006/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6931\n",
            "Epoch 9007/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6927\n",
            "Epoch 9008/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6926\n",
            "Epoch 9009/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 9010/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 9011/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6932\n",
            "Epoch 9012/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6929\n",
            "Epoch 9013/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6930\n",
            "Epoch 9014/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 9015/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6923 - d_loss: 0.6931\n",
            "Epoch 9016/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6930\n",
            "Epoch 9017/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6929\n",
            "Epoch 9018/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6931\n",
            "Epoch 9019/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6931\n",
            "Epoch 9020/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 9021/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6930 - d_loss: 0.6930\n",
            "Epoch 9022/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6932\n",
            "Epoch 9023/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6930\n",
            "Epoch 9024/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6935\n",
            "Epoch 9025/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 9026/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6931\n",
            "Epoch 9027/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 9028/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6925 - d_loss: 0.6929\n",
            "Epoch 9029/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9030/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6932\n",
            "Epoch 9031/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6930\n",
            "Epoch 9032/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6925 - d_loss: 0.6931\n",
            "Epoch 9033/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 9034/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6932\n",
            "Epoch 9035/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 9036/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9037/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6930\n",
            "Epoch 9038/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 9039/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 9040/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9041/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9042/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 9043/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 9044/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6932\n",
            "Epoch 9045/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9046/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 9047/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 9048/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 9049/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6935\n",
            "Epoch 9050/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 9051/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9052/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 9053/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 9054/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9055/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9056/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 9057/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 9058/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 9059/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 9060/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 9061/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 9062/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9063/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6932\n",
            "Epoch 9064/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 9065/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 9066/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 9067/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 9068/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 9069/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 9070/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 9071/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6934\n",
            "Epoch 9072/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9073/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 9074/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 9075/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6933\n",
            "Epoch 9076/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 9077/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6932\n",
            "Epoch 9078/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 9079/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 9080/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 9081/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9082/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6933\n",
            "Epoch 9083/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6936\n",
            "Epoch 9084/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 9085/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9086/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 9087/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9088/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6934\n",
            "Epoch 9089/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 9090/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6936\n",
            "Epoch 9091/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6932\n",
            "Epoch 9092/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 9093/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6933\n",
            "Epoch 9094/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6933\n",
            "Epoch 9095/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6935\n",
            "Epoch 9096/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9097/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6935\n",
            "Epoch 9098/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6936\n",
            "Epoch 9099/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6934\n",
            "Epoch 9100/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6931\n",
            "Epoch 9101/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9102/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6935\n",
            "Epoch 9103/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 9104/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6930\n",
            "Epoch 9105/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 9106/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6936\n",
            "Epoch 9107/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 9108/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 9109/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 9110/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9111/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 9112/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6934\n",
            "Epoch 9113/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6937\n",
            "Epoch 9114/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 9115/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 9116/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 9117/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6932\n",
            "Epoch 9118/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6935\n",
            "Epoch 9119/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 9120/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 9121/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 9122/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9123/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 9124/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9125/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 9126/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 9127/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 9128/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 9129/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6934\n",
            "Epoch 9130/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9131/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6936\n",
            "Epoch 9132/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6934\n",
            "Epoch 9133/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6934\n",
            "Epoch 9134/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6933\n",
            "Epoch 9135/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 9136/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 9137/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6934\n",
            "Epoch 9138/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6934\n",
            "Epoch 9139/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 9140/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6934\n",
            "Epoch 9141/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 9142/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 9143/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6935\n",
            "Epoch 9144/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 9145/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6937\n",
            "Epoch 9146/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6934\n",
            "Epoch 9147/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6935\n",
            "Epoch 9148/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 9149/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 9150/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6929 - d_loss: 0.6935\n",
            "Epoch 9151/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 9152/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6935\n",
            "Epoch 9153/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6935\n",
            "Epoch 9154/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6930 - d_loss: 0.6936\n",
            "Epoch 9155/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9156/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6935\n",
            "Epoch 9157/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6934\n",
            "Epoch 9158/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6939\n",
            "Epoch 9159/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6935\n",
            "Epoch 9160/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6936\n",
            "Epoch 9161/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6936\n",
            "Epoch 9162/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6933\n",
            "Epoch 9163/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6934\n",
            "Epoch 9164/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6934\n",
            "Epoch 9165/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6935\n",
            "Epoch 9166/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6933\n",
            "Epoch 9167/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6933\n",
            "Epoch 9168/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6936\n",
            "Epoch 9169/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 9170/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9171/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6934\n",
            "Epoch 9172/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6936\n",
            "Epoch 9173/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6936\n",
            "Epoch 9174/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 9175/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6925 - d_loss: 0.6937\n",
            "Epoch 9176/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 9177/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6936\n",
            "Epoch 9178/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6930 - d_loss: 0.6937\n",
            "Epoch 9179/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6934\n",
            "Epoch 9180/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 9181/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6938\n",
            "Epoch 9182/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6936\n",
            "Epoch 9183/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 9184/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9185/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6923 - d_loss: 0.6933\n",
            "Epoch 9186/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6936\n",
            "Epoch 9187/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 9188/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6923 - d_loss: 0.6934\n",
            "Epoch 9189/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6935\n",
            "Epoch 9190/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 9191/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6936\n",
            "Epoch 9192/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6935\n",
            "Epoch 9193/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6935\n",
            "Epoch 9194/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9195/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6925 - d_loss: 0.6934\n",
            "Epoch 9196/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6936\n",
            "Epoch 9197/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6925 - d_loss: 0.6935\n",
            "Epoch 9198/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 9199/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6936\n",
            "Epoch 9200/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 9201/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6935\n",
            "Epoch 9202/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6935\n",
            "Epoch 9203/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6934\n",
            "Epoch 9204/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6930 - d_loss: 0.6937\n",
            "Epoch 9205/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 9206/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6936\n",
            "Epoch 9207/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9208/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6934\n",
            "Epoch 9209/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9210/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 9211/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6933\n",
            "Epoch 9212/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6935\n",
            "Epoch 9213/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6925 - d_loss: 0.6936\n",
            "Epoch 9214/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6924 - d_loss: 0.6934\n",
            "Epoch 9215/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6922 - d_loss: 0.6936\n",
            "Epoch 9216/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6920 - d_loss: 0.6935\n",
            "Epoch 9217/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6935\n",
            "Epoch 9218/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6933\n",
            "Epoch 9219/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6923 - d_loss: 0.6937\n",
            "Epoch 9220/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6920 - d_loss: 0.6933\n",
            "Epoch 9221/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 9222/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6934\n",
            "Epoch 9223/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6924 - d_loss: 0.6935\n",
            "Epoch 9224/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 9225/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6936\n",
            "Epoch 9226/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6937\n",
            "Epoch 9227/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9228/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6934\n",
            "Epoch 9229/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6924 - d_loss: 0.6932\n",
            "Epoch 9230/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6934\n",
            "Epoch 9231/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6935\n",
            "Epoch 9232/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6934\n",
            "Epoch 9233/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6929 - d_loss: 0.6937\n",
            "Epoch 9234/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6923 - d_loss: 0.6934\n",
            "Epoch 9235/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6923 - d_loss: 0.6932\n",
            "Epoch 9236/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6937\n",
            "Epoch 9237/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 9238/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9239/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 9240/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6935\n",
            "Epoch 9241/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6934\n",
            "Epoch 9242/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6925 - d_loss: 0.6935\n",
            "Epoch 9243/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6933\n",
            "Epoch 9244/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6934\n",
            "Epoch 9245/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6934\n",
            "Epoch 9246/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6928 - d_loss: 0.6935\n",
            "Epoch 9247/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6929 - d_loss: 0.6935\n",
            "Epoch 9248/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9249/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6936\n",
            "Epoch 9250/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6935\n",
            "Epoch 9251/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6937\n",
            "Epoch 9252/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 9253/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6926 - d_loss: 0.6936\n",
            "Epoch 9254/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6934\n",
            "Epoch 9255/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6934\n",
            "Epoch 9256/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6925 - d_loss: 0.6936\n",
            "Epoch 9257/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9258/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6925 - d_loss: 0.6934\n",
            "Epoch 9259/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9260/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6931\n",
            "Epoch 9261/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6924 - d_loss: 0.6935\n",
            "Epoch 9262/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 9263/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6935\n",
            "Epoch 9264/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6936\n",
            "Epoch 9265/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6935\n",
            "Epoch 9266/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6925 - d_loss: 0.6937\n",
            "Epoch 9267/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6933\n",
            "Epoch 9268/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6935\n",
            "Epoch 9269/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6935\n",
            "Epoch 9270/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 9271/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6935\n",
            "Epoch 9272/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6934\n",
            "Epoch 9273/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6936\n",
            "Epoch 9274/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 9275/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6925 - d_loss: 0.6936\n",
            "Epoch 9276/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6936\n",
            "Epoch 9277/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 9278/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6925 - d_loss: 0.6934\n",
            "Epoch 9279/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6935\n",
            "Epoch 9280/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 9281/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6926 - d_loss: 0.6934\n",
            "Epoch 9282/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6925 - d_loss: 0.6934\n",
            "Epoch 9283/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6925 - d_loss: 0.6935\n",
            "Epoch 9284/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9285/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 9286/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6933\n",
            "Epoch 9287/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6935\n",
            "Epoch 9288/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 9289/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9290/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 9291/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6936\n",
            "Epoch 9292/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6935\n",
            "Epoch 9293/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6935\n",
            "Epoch 9294/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 9295/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6936\n",
            "Epoch 9296/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 9297/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6936\n",
            "Epoch 9298/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6935\n",
            "Epoch 9299/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6935\n",
            "Epoch 9300/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 9301/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 9302/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6934\n",
            "Epoch 9303/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 9304/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6935\n",
            "Epoch 9305/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6935\n",
            "Epoch 9306/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 9307/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 9308/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6936\n",
            "Epoch 9309/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6936\n",
            "Epoch 9310/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 9311/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6935\n",
            "Epoch 9312/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6935\n",
            "Epoch 9313/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9314/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 9315/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6935\n",
            "Epoch 9316/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 9317/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6935\n",
            "Epoch 9318/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6936\n",
            "Epoch 9319/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 9320/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6935\n",
            "Epoch 9321/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6935\n",
            "Epoch 9322/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6935\n",
            "Epoch 9323/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6934\n",
            "Epoch 9324/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6934\n",
            "Epoch 9325/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6935\n",
            "Epoch 9326/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6932\n",
            "Epoch 9327/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 9328/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6934\n",
            "Epoch 9329/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6935\n",
            "Epoch 9330/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6934\n",
            "Epoch 9331/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6935\n",
            "Epoch 9332/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6934\n",
            "Epoch 9333/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 9334/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6936\n",
            "Epoch 9335/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 9336/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 9337/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6933\n",
            "Epoch 9338/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9339/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 9340/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 9341/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9342/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 9343/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6933\n",
            "Epoch 9344/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6933\n",
            "Epoch 9345/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 9346/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9347/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9348/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6933\n",
            "Epoch 9349/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9350/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6931\n",
            "Epoch 9351/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 9352/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 9353/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 9354/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6934\n",
            "Epoch 9355/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6935\n",
            "Epoch 9356/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 9357/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 9358/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6934\n",
            "Epoch 9359/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 9360/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6934\n",
            "Epoch 9361/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6933\n",
            "Epoch 9362/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6932\n",
            "Epoch 9363/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 9364/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 9365/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 9366/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 9367/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 9368/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 9369/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 9370/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6932\n",
            "Epoch 9371/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6931\n",
            "Epoch 9372/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 9373/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6932\n",
            "Epoch 9374/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 9375/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6933\n",
            "Epoch 9376/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 9377/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6931\n",
            "Epoch 9378/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 9379/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6933\n",
            "Epoch 9380/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6933\n",
            "Epoch 9381/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6931\n",
            "Epoch 9382/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9383/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 9384/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 9385/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 9386/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 9387/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 9388/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 9389/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9390/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 9391/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9392/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6931\n",
            "Epoch 9393/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6929\n",
            "Epoch 9394/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6936 - d_loss: 0.6933\n",
            "Epoch 9395/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 9396/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6931\n",
            "Epoch 9397/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6930\n",
            "Epoch 9398/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6932\n",
            "Epoch 9399/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6932\n",
            "Epoch 9400/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6930\n",
            "Epoch 9401/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 9402/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6930\n",
            "Epoch 9403/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6933\n",
            "Epoch 9404/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 9405/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6931\n",
            "Epoch 9406/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 9407/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 9408/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6937 - d_loss: 0.6932\n",
            "Epoch 9409/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 9410/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6930\n",
            "Epoch 9411/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6931\n",
            "Epoch 9412/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 9413/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6931\n",
            "Epoch 9414/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6930\n",
            "Epoch 9415/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6931\n",
            "Epoch 9416/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6932\n",
            "Epoch 9417/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 9418/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9419/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 9420/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9421/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9422/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6929\n",
            "Epoch 9423/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 9424/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6932\n",
            "Epoch 9425/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9426/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 9427/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 9428/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 9429/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 9430/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 9431/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9432/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 9433/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 9434/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6932\n",
            "Epoch 9435/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 9436/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9437/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 9438/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9439/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6929\n",
            "Epoch 9440/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 9441/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 9442/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9443/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 9444/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9445/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6930\n",
            "Epoch 9446/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9447/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 9448/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 9449/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9450/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 9451/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6928\n",
            "Epoch 9452/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9453/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6929\n",
            "Epoch 9454/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6930\n",
            "Epoch 9455/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9456/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9457/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 9458/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 9459/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9460/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 9461/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 9462/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6928\n",
            "Epoch 9463/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6929\n",
            "Epoch 9464/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 9465/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 9466/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6927\n",
            "Epoch 9467/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9468/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 9469/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 9470/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 9471/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 9472/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6929\n",
            "Epoch 9473/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 9474/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 9475/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6938 - d_loss: 0.6929\n",
            "Epoch 9476/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 9477/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 9478/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 9479/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 9480/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 9481/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 9482/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 9483/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 9484/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 9485/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 9486/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9487/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 9488/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9489/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 9490/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9491/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 9492/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 9493/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9494/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 9495/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 9496/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9497/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9498/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9499/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9500/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9501/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 9502/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9503/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 9504/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 9505/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6929\n",
            "Epoch 9506/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9507/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6926\n",
            "Epoch 9508/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 9509/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9510/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 9511/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 9512/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9513/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9514/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9515/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6938 - d_loss: 0.6929\n",
            "Epoch 9516/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6928\n",
            "Epoch 9517/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9518/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6929\n",
            "Epoch 9519/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9520/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9521/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9522/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9523/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 9524/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6944 - d_loss: 0.6929\n",
            "Epoch 9525/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 9526/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9527/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6929\n",
            "Epoch 9528/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6927\n",
            "Epoch 9529/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9530/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6942 - d_loss: 0.6928\n",
            "Epoch 9531/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6946 - d_loss: 0.6926\n",
            "Epoch 9532/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6945 - d_loss: 0.6927\n",
            "Epoch 9533/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6944 - d_loss: 0.6928\n",
            "Epoch 9534/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 9535/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9536/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6927\n",
            "Epoch 9537/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 9538/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6928\n",
            "Epoch 9539/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6928\n",
            "Epoch 9540/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6929\n",
            "Epoch 9541/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9542/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9543/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 9544/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 9545/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9546/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6927\n",
            "Epoch 9547/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6947 - d_loss: 0.6926\n",
            "Epoch 9548/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 9549/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6946 - d_loss: 0.6925\n",
            "Epoch 9550/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 9551/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 9552/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6945 - d_loss: 0.6927\n",
            "Epoch 9553/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 9554/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6945 - d_loss: 0.6925\n",
            "Epoch 9555/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 9556/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6927\n",
            "Epoch 9557/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9558/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 9559/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9560/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9561/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9562/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 9563/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 9564/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9565/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9566/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6925\n",
            "Epoch 9567/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6925\n",
            "Epoch 9568/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 9569/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6925\n",
            "Epoch 9570/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6946 - d_loss: 0.6926\n",
            "Epoch 9571/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6944 - d_loss: 0.6928\n",
            "Epoch 9572/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 9573/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 9574/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9575/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 9576/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6945 - d_loss: 0.6928\n",
            "Epoch 9577/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6928\n",
            "Epoch 9578/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6925\n",
            "Epoch 9579/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 9580/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9581/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 9582/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9583/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9584/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9585/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 9586/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 9587/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6926\n",
            "Epoch 9588/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6925\n",
            "Epoch 9589/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9590/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 9591/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6926\n",
            "Epoch 9592/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9593/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9594/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6945 - d_loss: 0.6925\n",
            "Epoch 9595/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 9596/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9597/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9598/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6926\n",
            "Epoch 9599/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 9600/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6926\n",
            "Epoch 9601/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6944 - d_loss: 0.6927\n",
            "Epoch 9602/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6945 - d_loss: 0.6925\n",
            "Epoch 9603/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 9604/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6940 - d_loss: 0.6925\n",
            "Epoch 9605/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 9606/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6944 - d_loss: 0.6929\n",
            "Epoch 9607/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 9608/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 9609/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6925\n",
            "Epoch 9610/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6925\n",
            "Epoch 9611/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6925\n",
            "Epoch 9612/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6924\n",
            "Epoch 9613/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 9614/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9615/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 9616/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6926\n",
            "Epoch 9617/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6924\n",
            "Epoch 9618/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9619/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6925\n",
            "Epoch 9620/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6928\n",
            "Epoch 9621/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 9622/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 9623/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 9624/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6924\n",
            "Epoch 9625/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6926\n",
            "Epoch 9626/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6926\n",
            "Epoch 9627/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9628/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9629/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 9630/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9631/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 9632/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 9633/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9634/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 9635/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 9636/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6924\n",
            "Epoch 9637/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6926\n",
            "Epoch 9638/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6927\n",
            "Epoch 9639/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6926\n",
            "Epoch 9640/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 9641/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 9642/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9643/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 9644/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 9645/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 9646/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6924\n",
            "Epoch 9647/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 9648/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9649/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9650/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9651/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9652/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 9653/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 9654/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 9655/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6926\n",
            "Epoch 9656/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6926\n",
            "Epoch 9657/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6924\n",
            "Epoch 9658/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6935 - d_loss: 0.6925\n",
            "Epoch 9659/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6925\n",
            "Epoch 9660/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9661/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6924\n",
            "Epoch 9662/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 9663/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9664/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 9665/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 9666/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9667/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 9668/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9669/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 9670/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6932 - d_loss: 0.6927\n",
            "Epoch 9671/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9672/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 9673/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9674/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 9675/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9676/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9677/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 9678/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9679/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 9680/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9681/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 9682/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6926\n",
            "Epoch 9683/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 9684/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9685/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9686/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 9687/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 9688/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9689/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 9690/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 9691/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 9692/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 9693/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9694/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 9695/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 9696/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9697/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9698/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 9699/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6942 - d_loss: 0.6927\n",
            "Epoch 9700/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9701/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6930\n",
            "Epoch 9702/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9703/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9704/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 9705/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 9706/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 9707/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9708/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 9709/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6927\n",
            "Epoch 9710/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6925\n",
            "Epoch 9711/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6943 - d_loss: 0.6927\n",
            "Epoch 9712/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6926\n",
            "Epoch 9713/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 9714/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6929\n",
            "Epoch 9715/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 9716/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 9717/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9718/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 9719/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 9720/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9721/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6925\n",
            "Epoch 9722/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9723/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9724/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9725/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6926\n",
            "Epoch 9726/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9727/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9728/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9729/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6925\n",
            "Epoch 9730/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 9731/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9732/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9733/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 9734/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 9735/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 9736/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6928\n",
            "Epoch 9737/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9738/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 9739/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9740/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6941 - d_loss: 0.6928\n",
            "Epoch 9741/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9742/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9743/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 9744/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9745/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9746/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6926\n",
            "Epoch 9747/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9748/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9749/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 9750/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9751/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9752/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9753/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9754/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6926\n",
            "Epoch 9755/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9756/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6925\n",
            "Epoch 9757/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9758/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9759/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9760/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9761/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6929\n",
            "Epoch 9762/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9763/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9764/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 9765/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9766/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9767/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 9768/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9769/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9770/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9771/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6925\n",
            "Epoch 9772/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 9773/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9774/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 9775/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9776/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6929\n",
            "Epoch 9777/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6927\n",
            "Epoch 9778/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 9779/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9780/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9781/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6929\n",
            "Epoch 9782/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6928\n",
            "Epoch 9783/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6930\n",
            "Epoch 9784/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9785/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9786/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9787/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9788/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6929\n",
            "Epoch 9789/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9790/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9791/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9792/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6928\n",
            "Epoch 9793/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 9794/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 9795/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 9796/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6929\n",
            "Epoch 9797/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9798/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6928\n",
            "Epoch 9799/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6936 - d_loss: 0.6926\n",
            "Epoch 9800/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 9801/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9802/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9803/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6927\n",
            "Epoch 9804/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 9805/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9806/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6929\n",
            "Epoch 9807/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6930\n",
            "Epoch 9808/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6927\n",
            "Epoch 9809/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9810/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6926\n",
            "Epoch 9811/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 9812/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9813/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6930\n",
            "Epoch 9814/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 9815/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6928\n",
            "Epoch 9816/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6929\n",
            "Epoch 9817/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9818/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 9819/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 9820/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6939 - d_loss: 0.6927\n",
            "Epoch 9821/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9822/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 9823/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6929\n",
            "Epoch 9824/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6928\n",
            "Epoch 9825/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9826/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9827/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6927\n",
            "Epoch 9828/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9829/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 9830/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 9831/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 9832/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9833/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 9834/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6929\n",
            "Epoch 9835/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9836/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6927\n",
            "Epoch 9837/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6929\n",
            "Epoch 9838/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6927\n",
            "Epoch 9839/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6926\n",
            "Epoch 9840/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6928\n",
            "Epoch 9841/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 9842/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 9843/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 9844/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 9845/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 9846/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9847/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9848/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6931\n",
            "Epoch 9849/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9850/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6930\n",
            "Epoch 9851/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 9852/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9853/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6928\n",
            "Epoch 9854/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9855/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 9856/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 9857/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 9858/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9859/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6938 - d_loss: 0.6929\n",
            "Epoch 9860/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9861/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9862/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 9863/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 9864/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 9865/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9866/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6928\n",
            "Epoch 9867/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6928\n",
            "Epoch 9868/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 9869/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6928\n",
            "Epoch 9870/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6929\n",
            "Epoch 9871/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6929\n",
            "Epoch 9872/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6931\n",
            "Epoch 9873/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6930\n",
            "Epoch 9874/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9875/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 9876/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9877/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 9878/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6940 - d_loss: 0.6929\n",
            "Epoch 9879/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 9880/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9881/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 9882/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 9883/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9884/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 9885/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 9886/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6928\n",
            "Epoch 9887/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 9888/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 9889/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6929\n",
            "Epoch 9890/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 9891/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 9892/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 9893/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6930\n",
            "Epoch 9894/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6927\n",
            "Epoch 9895/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6929\n",
            "Epoch 9896/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6929\n",
            "Epoch 9897/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 9898/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 9899/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 9900/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9901/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 9902/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6930\n",
            "Epoch 9903/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 9904/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6931\n",
            "Epoch 9905/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6929\n",
            "Epoch 9906/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 9907/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6929 - d_loss: 0.6931\n",
            "Epoch 9908/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 9909/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6931\n",
            "Epoch 9910/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6930\n",
            "Epoch 9911/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9912/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9913/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6932\n",
            "Epoch 9914/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9915/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 9916/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6928 - d_loss: 0.6930\n",
            "Epoch 9917/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6931\n",
            "Epoch 9918/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 9919/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6932\n",
            "Epoch 9920/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 9921/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 9922/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 9923/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 9924/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 9925/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 9926/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6938 - d_loss: 0.6930\n",
            "Epoch 9927/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6931\n",
            "Epoch 9928/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9929/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 9930/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6930\n",
            "Epoch 9931/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6937 - d_loss: 0.6931\n",
            "Epoch 9932/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 9933/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 9934/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 9935/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9936/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 9937/10000\n",
            "36/36 [==============================] - 0s 4ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9938/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 9939/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6929\n",
            "Epoch 9940/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6930\n",
            "Epoch 9941/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 9942/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 9943/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9944/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6934 - d_loss: 0.6931\n",
            "Epoch 9945/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 9946/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 9947/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6936 - d_loss: 0.6931\n",
            "Epoch 9948/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9949/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9950/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6930\n",
            "Epoch 9951/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6930\n",
            "Epoch 9952/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6931\n",
            "Epoch 9953/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9954/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 9955/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9956/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9957/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6931\n",
            "Epoch 9958/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9959/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6932\n",
            "Epoch 9960/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 9961/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9962/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9963/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 9964/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 9965/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 9966/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 9967/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 9968/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 9969/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 9970/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 9971/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6931\n",
            "Epoch 9972/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9973/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6931\n",
            "Epoch 9974/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6927 - d_loss: 0.6932\n",
            "Epoch 9975/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6934\n",
            "Epoch 9976/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 9977/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6927 - d_loss: 0.6932\n",
            "Epoch 9978/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6933\n",
            "Epoch 9979/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 9980/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6929 - d_loss: 0.6932\n",
            "Epoch 9981/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 9982/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9983/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6932 - d_loss: 0.6932\n",
            "Epoch 9984/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6933\n",
            "Epoch 9985/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6933\n",
            "Epoch 9986/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 9987/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6932\n",
            "Epoch 9988/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6932\n",
            "Epoch 9989/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9990/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9991/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6934 - d_loss: 0.6934\n",
            "Epoch 9992/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6928 - d_loss: 0.6932\n",
            "Epoch 9993/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6932\n",
            "Epoch 9994/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9995/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6931 - d_loss: 0.6931\n",
            "Epoch 9996/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6935 - d_loss: 0.6932\n",
            "Epoch 9997/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6930 - d_loss: 0.6934\n",
            "Epoch 9998/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6933\n",
            "Epoch 9999/10000\n",
            "36/36 [==============================] - 0s 6ms/step - g_loss: 0.6933 - d_loss: 0.6934\n",
            "Epoch 10000/10000\n",
            "36/36 [==============================] - 0s 5ms/step - g_loss: 0.6933 - d_loss: 0.6934\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f9e2dbed0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cgan.fit(dataset, epochs=10000, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnUkQDJ3uC72"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "QWYYAtVAuC72",
        "outputId": "3910846d-8a8e-441f-e76b-6a1446882764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating:  231  ages for unit type: [1., 0., 0.]\n",
            "Generated Ages:\n",
            "min:  19.87695050239563\n",
            "mean:  54.41687184856052\n",
            "max:  86.09775269031525\n",
            "stdv:  15.853573192964298\n",
            "True Ages:\n",
            "min:  19\n",
            "mean:  56.15151515151515\n",
            "max:  90\n",
            "stdv:  16.825009339158104\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"Generate n ages for a class\"\"\"\n",
        "print(\"Generating: \", 231, \" ages for unit type: [1., 0., 0.]\")\n",
        "\n",
        "age_one_hot_labels = tf.repeat([[1., 0., 0.]],231, axis=0)\n",
        "\n",
        "input_noise = tf.random.normal((231, cgan.noise_dim), 0, 1)\n",
        "random_vector_labels = tf.concat([input_noise, age_one_hot_labels], axis=1)\n",
        "\n",
        "ages = cgan.generator(random_vector_labels)\n",
        "\n",
        "inv_gen_ages = [(val * (max_age_filtered-min_age_filtered)) + min_age_filtered for val in ages.numpy().flatten()]\n",
        "\n",
        "print(\"Generated Ages:\")\n",
        "print(\"min: \", np.min(inv_gen_ages))\n",
        "print(\"mean: \", np.mean(inv_gen_ages))\n",
        "print(\"max: \", np.max(inv_gen_ages))\n",
        "print(\"stdv: \", np.std(inv_gen_ages))\n",
        "\n",
        "df_ages_class = final_df.query(\"ethnicity == 'African American'\")\n",
        "\n",
        "print(\"True Ages:\")\n",
        "print(\"min: \", np.min(df_ages_class.age))\n",
        "print(\"mean: \", np.mean(df_ages_class.age))\n",
        "print(\"max: \", np.max(df_ages_class.age))\n",
        "print(\"stdv: \", np.std(df_ages_class.age))\n",
        "\n",
        "\n",
        "sns.histplot(inv_gen_ages, bins=70, label='GAN', kde=True,)\n",
        "sns.histplot(df_ages_class.age, bins=70, color='orange', label='Truth', alpha=0.3, kde=True,)\n",
        "plt.title('African American Ages')\n",
        "plt.legend()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "drwqfXpEuC73",
        "outputId": "da87c8d8-3746-4814-8957-cdeca5ebf8ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating:  2010  ages for unit type: [0., 1., 0.]\n",
            "Generated Ages:\n",
            "min:  17.105259001255035\n",
            "mean:  64.42795267769354\n",
            "max:  88.05495405197144\n",
            "stdv:  16.114971330292576\n",
            "True Ages:\n",
            "min:  15\n",
            "mean:  64.44378109452737\n",
            "max:  89\n",
            "stdv:  17.41515533822681\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"Generate n ages for a class\"\"\"\n",
        "print(\"Generating: \", 2010, \" ages for unit type: [0., 1., 0.]\")\n",
        "\n",
        "age_one_hot_labels = tf.repeat([[0., 1., 0.]],2010, axis=0)\n",
        "\n",
        "input_noise = tf.random.normal((2010, cgan.noise_dim), 0, 1)\n",
        "random_vector_labels = tf.concat([input_noise, age_one_hot_labels], axis=1)\n",
        "\n",
        "ages = cgan.generator(random_vector_labels)\n",
        "\n",
        "inv_gen_ages = [(val * (max_age_filtered-min_age_filtered)) + min_age_filtered for val in ages.numpy().flatten()]\n",
        "\n",
        "print(\"Generated Ages:\")\n",
        "print(\"min: \", np.min(inv_gen_ages))\n",
        "print(\"mean: \", np.mean(inv_gen_ages))\n",
        "print(\"max: \", np.max(inv_gen_ages))\n",
        "print(\"stdv: \", np.std(inv_gen_ages))\n",
        "\n",
        "df_ages_class = final_df.query(\"ethnicity == 'Caucasian'\")\n",
        "\n",
        "print(\"True Ages:\")\n",
        "print(\"min: \", np.min(df_ages_class.age))\n",
        "print(\"mean: \", np.mean(df_ages_class.age))\n",
        "print(\"max: \", np.max(df_ages_class.age))\n",
        "print(\"stdv: \", np.std(df_ages_class.age))\n",
        "\n",
        "\n",
        "sns.histplot(inv_gen_ages, bins=70, label='GAN', kde=True,)\n",
        "sns.histplot(df_ages_class.age, bins=70, color='orange', label='Truth', alpha=0.3, kde=True,)\n",
        "plt.title('Caucasian Ages')\n",
        "plt.legend()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "S1WvBkzMuC73",
        "outputId": "4829644d-9a5a-4edd-e6e6-221563d828e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9d9c445b-64bb-4587-8986-9be0c9b1bd31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">age</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ethnicity</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>African American</th>\n",
              "      <td>231.0</td>\n",
              "      <td>56.151515</td>\n",
              "      <td>16.861546</td>\n",
              "      <td>19.0</td>\n",
              "      <td>46.50</td>\n",
              "      <td>58.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Caucasian</th>\n",
              "      <td>2010.0</td>\n",
              "      <td>64.443781</td>\n",
              "      <td>17.419489</td>\n",
              "      <td>15.0</td>\n",
              "      <td>55.00</td>\n",
              "      <td>67.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>89.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Native American</th>\n",
              "      <td>12.0</td>\n",
              "      <td>50.500000</td>\n",
              "      <td>20.331346</td>\n",
              "      <td>19.0</td>\n",
              "      <td>39.25</td>\n",
              "      <td>48.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>88.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d9c445b-64bb-4587-8986-9be0c9b1bd31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d9c445b-64bb-4587-8986-9be0c9b1bd31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d9c445b-64bb-4587-8986-9be0c9b1bd31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     age                                                     \n",
              "                   count       mean        std   min    25%   50%   75%   max\n",
              "ethnicity                                                                    \n",
              "African American   231.0  56.151515  16.861546  19.0  46.50  58.0  69.0  90.0\n",
              "Caucasian         2010.0  64.443781  17.419489  15.0  55.00  67.0  78.0  89.0\n",
              "Native American     12.0  50.500000  20.331346  19.0  39.25  48.0  66.0  88.0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ages.groupby('ethnicity').describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "Z6odZ8N7uC73",
        "outputId": "62da67c5-6601-4041-9b71-b7dec95f9e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating:  12  ages for unit type: [0., 0., 1]\n",
            "Generated Ages:\n",
            "min:  25.443816304206848\n",
            "mean:  45.98120958109697\n",
            "max:  59.78450393676758\n",
            "stdv:  9.848682599013852\n",
            "True Ages:\n",
            "min:  19\n",
            "mean:  50.5\n",
            "max:  88\n",
            "stdv:  19.465781943365815\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"Generate n ages for a class\"\"\"\n",
        "print(\"Generating: \", 12, \" ages for unit type: [0., 0., 1]\")\n",
        "\n",
        "age_one_hot_labels = tf.repeat([[0., 0., 1.]],12, axis=0)\n",
        "\n",
        "input_noise = tf.random.normal((12, cgan.noise_dim), 0, 1)\n",
        "random_vector_labels = tf.concat([input_noise, age_one_hot_labels], axis=1)\n",
        "\n",
        "ages = cgan.generator(random_vector_labels)\n",
        "\n",
        "inv_gen_ages = [(val * (max_age_filtered-min_age_filtered)) + min_age_filtered for val in ages.numpy().flatten()]\n",
        "\n",
        "print(\"Generated Ages:\")\n",
        "print(\"min: \", np.min(inv_gen_ages))\n",
        "print(\"mean: \", np.mean(inv_gen_ages))\n",
        "print(\"max: \", np.max(inv_gen_ages))\n",
        "print(\"stdv: \", np.std(inv_gen_ages))\n",
        "\n",
        "df_ages_class = final_df.query(\"ethnicity == 'Native American'\")\n",
        "\n",
        "print(\"True Ages:\")\n",
        "print(\"min: \", np.min(df_ages_class.age))\n",
        "print(\"mean: \", np.mean(df_ages_class.age))\n",
        "print(\"max: \", np.max(df_ages_class.age))\n",
        "print(\"stdv: \", np.std(df_ages_class.age))\n",
        "\n",
        "\n",
        "sns.histplot(inv_gen_ages, bins=70, label='GAN', kde=True,)\n",
        "sns.histplot(df_ages_class.age, bins=70, color='orange', label='Truth', alpha=0.3, kde=True,)\n",
        "plt.title('Native American Ages')\n",
        "plt.legend()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_RCa2NLuC73"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "age_ethnicity_gan_DF.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "34b722ad9db4b3bab2fc22ea7ad4e4dafa3a71a0a38143cc4f1aba484bf1fe4b"
    },
    "kernelspec": {
      "display_name": "Python 3.9 (tensorflow)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
