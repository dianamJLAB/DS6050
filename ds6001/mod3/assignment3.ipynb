{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H. Diana McSpadden (hdm5s)\n",
    "\n",
    "# Lab Assignment 3: How to Load, Convert, and\n",
    "# Write JSON Files in Python\n",
    "## DS 6001: Practice and Application of Data Science\n",
    "### Instructions\n",
    "\n",
    "Please answer the following questions as completely as possible using text, code, and the\n",
    "results of code as needed. Format your answers in a Jupyter notebook. To receive full credit,\n",
    "make sure you address every part of the problem, and make sure your document is formatted in\n",
    "a clean and professional way.\n",
    "\n",
    "### Problem 0\n",
    "Import the following libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "sys.tracebacklimit = 0 # turn off the error tracebacks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "JSON and CSV are both text-based formats for the storage of data. It's possible to open either\n",
    "one in a plain text editor. Given this similarity, why does a CSV file usually take less memory than\n",
    "a JSON formatted file for the same data? Under what conditions could a JSON file be smaller in\n",
    "memory than a CSV file for the same data? (2 points)\n",
    "\n",
    "### Problem 1 Answer:\n",
    "The key value pair structure of JSON files may make JSON format more verbose. For example:\n",
    "\n",
    "```\n",
    "{\n",
    " \"name\": \"John Smith\",\n",
    " \"age\": 30,\n",
    " \"address\": {\n",
    "   \"street\": \"123 Main St\",\n",
    "   \"city\": \"Anytown\",\n",
    "   \"state\": \"CA\",\n",
    "   \"zip\": \"12345\"\n",
    " },\n",
    " \"phoneNumbers\": [\n",
    "   {\n",
    "     \"type\": \"home\",\n",
    "     \"number\": \"555-555-5555\"\n",
    "   },\n",
    "   {\n",
    "     \"type\": \"work\",\n",
    "     \"number\": \"555-555-5556\"\n",
    "   }\n",
    " ]\n",
    "}\n",
    "```\n",
    "\n",
    "vs. the CSV format:\n",
    "\n",
    "|name      | age | street | city  | state | zip | type | number |\n",
    "|-----------|-----------|----------|-----------|-----------|----------|-----------|----------|\n",
    "| John Smith    | 30        | 123       | Main St | Anytown, CA | 12345 | home | 555-555-5555 |\n",
    "| John Smith   | 30        | 123       | Main St | Anytown, CA | 12345 | work | 555-555-5555 |\n",
    "\n",
    "\n",
    "However, JSON could take a smaller amount of memory when the data contains a large number of nested objects such that the CSV format would result in flattening, i.e. repeating, quite a bit of information for all the nested objects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "NASA has a dataset of all meteorites that have fallen to Earth between the years A.D. 860 and\n",
    "2013. The data contain the name of each meteorite, along with the coordinates of the place\n",
    "where the meteorite hit, the mass of the meteorite, and the date of the collison. The data is\n",
    "stored as a JSON here: https://data.nasa.gov/resource/y77d-th95.json\n",
    "Look at the data in your web-browser and explain which strategy for loading the JSON into\n",
    "Python makes the most sense and why.\n",
    "Then write and run the code that will work for loading the data into Python. (2 points)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "The data includes name, id, nametype,recclass, mass, fall, year, reclat, reclong, geolocation {type, coordinates:list}. I would want to confirm, but eyeballing seems to show that the geolocation coordinates match the reclat and reclong coordinates.\n",
    "\n",
    "I will use the requests.get() method to retrieve the json from the url provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from the url in problem 2\n",
    "nasa_data = requests.get('https://data.nasa.gov/resource/y77d-th95.json').json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the first two results in the json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Aachen',\n",
       "  'id': '1',\n",
       "  'nametype': 'Valid',\n",
       "  'recclass': 'L5',\n",
       "  'mass': '21',\n",
       "  'fall': 'Fell',\n",
       "  'year': '1880-01-01T00:00:00.000',\n",
       "  'reclat': '50.775000',\n",
       "  'reclong': '6.083330',\n",
       "  'geolocation': {'type': 'Point', 'coordinates': [6.08333, 50.775]}},\n",
       " {'name': 'Aarhus',\n",
       "  'id': '2',\n",
       "  'nametype': 'Valid',\n",
       "  'recclass': 'H6',\n",
       "  'mass': '720',\n",
       "  'fall': 'Fell',\n",
       "  'year': '1951-01-01T00:00:00.000',\n",
       "  'reclat': '56.183330',\n",
       "  'reclong': '10.233330',\n",
       "  'geolocation': {'type': 'Point', 'coordinates': [10.23333, 56.18333]}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa_data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass</th>\n",
       "      <th>fall</th>\n",
       "      <th>year</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>1</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L5</td>\n",
       "      <td>21</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1880-01-01T00:00:00.000</td>\n",
       "      <td>50.775000</td>\n",
       "      <td>6.083330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aarhus</td>\n",
       "      <td>2</td>\n",
       "      <td>Valid</td>\n",
       "      <td>H6</td>\n",
       "      <td>720</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1951-01-01T00:00:00.000</td>\n",
       "      <td>56.183330</td>\n",
       "      <td>10.233330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name id nametype recclass mass  fall                     year     reclat  \\\n",
       "0  Aachen  1    Valid       L5   21  Fell  1880-01-01T00:00:00.000  50.775000   \n",
       "1  Aarhus  2    Valid       H6  720  Fell  1951-01-01T00:00:00.000  56.183330   \n",
       "\n",
       "     reclong  \n",
       "0   6.083330  \n",
       "1  10.233330  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the nasadata into a pandas dataframe\n",
    "nasa_df = pd.DataFrame(nasa_data)\n",
    "nasa_df = nasa_df[['name','id','nametype','recclass','mass','fall','year','reclat','reclong']]\n",
    "nasa_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "The textbook chapter for this module shows, as an example, how to pull data in JSON format\n",
    "from Reddit's top 25 posts on /r/popular. The steps outlined there pull all of the features in the\n",
    "data into the dataframe, resulting in a dataframe with 172 columns.\n",
    "If we only wanted a few features, then looping across elements of the JSON list itself and\n",
    "extracting only the data we want may be a more efficient approach.\n",
    "\n",
    "\n",
    "Use looping - and not pd.read_json() or pd.json_normalize() - to create a dataframe\n",
    "with 25 rows (one for each of the top 25 posts), and only columns for subreddit , title ,\n",
    "ups , and created_utc . The JSON file exists at http://www.reddit.com/r/popular/top.json,\n",
    "and don't forget to specify headers = {'User-agent': 'DS6001'} within\n",
    "requests.get() . (3 points)\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MadeMeSmile</td>\n",
       "      <td>Mad respect to both of them</td>\n",
       "      <td>101485</td>\n",
       "      <td>1.674849e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meirl</td>\n",
       "      <td>Meirl</td>\n",
       "      <td>90717</td>\n",
       "      <td>1.674851e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wholesomememes</td>\n",
       "      <td>Stage 3 breast, stage 1 breast, stage 3 small ...</td>\n",
       "      <td>90428</td>\n",
       "      <td>1.674857e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td>Silverback sees a little girl banging her ches...</td>\n",
       "      <td>84201</td>\n",
       "      <td>1.674841e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>antiwork</td>\n",
       "      <td>very striking</td>\n",
       "      <td>80861</td>\n",
       "      <td>1.674839e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>therewasanattempt</td>\n",
       "      <td>to be a dj</td>\n",
       "      <td>79062</td>\n",
       "      <td>1.674839e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>todayilearned</td>\n",
       "      <td>TIL Fender Guitars did a study and found that ...</td>\n",
       "      <td>73566</td>\n",
       "      <td>1.674847e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td>Cat broke into Lynx's cage and now they are be...</td>\n",
       "      <td>72659</td>\n",
       "      <td>1.674846e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>funny</td>\n",
       "      <td>My mom is diabetic. She eats Rockets to raise ...</td>\n",
       "      <td>71933</td>\n",
       "      <td>1.674833e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>interestingasfuck</td>\n",
       "      <td>On June 27th 1999, Tony Hawk became the worlds...</td>\n",
       "      <td>71457</td>\n",
       "      <td>1.674858e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>news</td>\n",
       "      <td>Tyre Nichols: Memphis police release body cam ...</td>\n",
       "      <td>71422</td>\n",
       "      <td>1.674864e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>Japanese Govt Set to Legalize Medical Marijuana</td>\n",
       "      <td>67256</td>\n",
       "      <td>1.674831e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unexpected</td>\n",
       "      <td>i would shit my pants</td>\n",
       "      <td>63210</td>\n",
       "      <td>1.674859e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WhitePeopleTwitter</td>\n",
       "      <td>This is horrific</td>\n",
       "      <td>62688</td>\n",
       "      <td>1.674867e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ContagiousLaughter</td>\n",
       "      <td>Roll down window prank.</td>\n",
       "      <td>61048</td>\n",
       "      <td>1.674840e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>comics</td>\n",
       "      <td>Any other available job openings?</td>\n",
       "      <td>58269</td>\n",
       "      <td>1.674864e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Damnthatsinteresting</td>\n",
       "      <td>After the death of her husband &amp;amp; with no b...</td>\n",
       "      <td>56686</td>\n",
       "      <td>1.674846e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Whatcouldgowrong</td>\n",
       "      <td>WCGW leaving the van in neutral</td>\n",
       "      <td>52861</td>\n",
       "      <td>1.674832e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Unexpected</td>\n",
       "      <td>Having older brothers.</td>\n",
       "      <td>48652</td>\n",
       "      <td>1.674842e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wholesomememes</td>\n",
       "      <td>terry crews is a national treasure</td>\n",
       "      <td>49061</td>\n",
       "      <td>1.674854e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>news</td>\n",
       "      <td>‘You’re going to see acts that defy humanity,’...</td>\n",
       "      <td>46475</td>\n",
       "      <td>1.674834e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IdiotsInCars</td>\n",
       "      <td>Tried to cut me off and instantly regretted it.</td>\n",
       "      <td>44007</td>\n",
       "      <td>1.674849e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>WhitePeopleTwitter</td>\n",
       "      <td>Red state America needs a civics lesson if the...</td>\n",
       "      <td>42251</td>\n",
       "      <td>1.674835e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MaliciousCompliance</td>\n",
       "      <td>Boss says \"If you're 1 minute late I'm docking...</td>\n",
       "      <td>42193</td>\n",
       "      <td>1.674831e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ContagiousLaughter</td>\n",
       "      <td>This is how you do a travel video</td>\n",
       "      <td>42819</td>\n",
       "      <td>1.674873e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               subreddit                                              title  \\\n",
       "0            MadeMeSmile                        Mad respect to both of them   \n",
       "1                  meirl                                              Meirl   \n",
       "2         wholesomememes  Stage 3 breast, stage 1 breast, stage 3 small ...   \n",
       "3       nextfuckinglevel  Silverback sees a little girl banging her ches...   \n",
       "4               antiwork                                      very striking   \n",
       "5      therewasanattempt                                         to be a dj   \n",
       "6          todayilearned  TIL Fender Guitars did a study and found that ...   \n",
       "7       nextfuckinglevel  Cat broke into Lynx's cage and now they are be...   \n",
       "8                  funny  My mom is diabetic. She eats Rockets to raise ...   \n",
       "9      interestingasfuck  On June 27th 1999, Tony Hawk became the worlds...   \n",
       "10                  news  Tyre Nichols: Memphis police release body cam ...   \n",
       "11             worldnews    Japanese Govt Set to Legalize Medical Marijuana   \n",
       "12            Unexpected                              i would shit my pants   \n",
       "13    WhitePeopleTwitter                                   This is horrific   \n",
       "14    ContagiousLaughter                            Roll down window prank.   \n",
       "15                comics                  Any other available job openings?   \n",
       "16  Damnthatsinteresting  After the death of her husband &amp; with no b...   \n",
       "17      Whatcouldgowrong                    WCGW leaving the van in neutral   \n",
       "18            Unexpected                             Having older brothers.   \n",
       "19        wholesomememes                 terry crews is a national treasure   \n",
       "20                  news  ‘You’re going to see acts that defy humanity,’...   \n",
       "21          IdiotsInCars    Tried to cut me off and instantly regretted it.   \n",
       "22    WhitePeopleTwitter  Red state America needs a civics lesson if the...   \n",
       "23   MaliciousCompliance  Boss says \"If you're 1 minute late I'm docking...   \n",
       "24    ContagiousLaughter                  This is how you do a travel video   \n",
       "\n",
       "       ups   created_utc  \n",
       "0   101485  1.674849e+09  \n",
       "1    90717  1.674851e+09  \n",
       "2    90428  1.674857e+09  \n",
       "3    84201  1.674841e+09  \n",
       "4    80861  1.674839e+09  \n",
       "5    79062  1.674839e+09  \n",
       "6    73566  1.674847e+09  \n",
       "7    72659  1.674846e+09  \n",
       "8    71933  1.674833e+09  \n",
       "9    71457  1.674858e+09  \n",
       "10   71422  1.674864e+09  \n",
       "11   67256  1.674831e+09  \n",
       "12   63210  1.674859e+09  \n",
       "13   62688  1.674867e+09  \n",
       "14   61048  1.674840e+09  \n",
       "15   58269  1.674864e+09  \n",
       "16   56686  1.674846e+09  \n",
       "17   52861  1.674832e+09  \n",
       "18   48652  1.674842e+09  \n",
       "19   49061  1.674854e+09  \n",
       "20   46475  1.674834e+09  \n",
       "21   44007  1.674849e+09  \n",
       "22   42251  1.674835e+09  \n",
       "23   42193  1.674831e+09  \n",
       "24   42819  1.674873e+09  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty pandas DataFrame\n",
    "df_reddit = pd.DataFrame()\n",
    "\n",
    "url = \"http://www.reddit.com/r/popular/top.json\"\n",
    "columns = ['subreddit' , 'title' ,'ups' , 'created_utc']\n",
    "reddit = requests.get(url, headers = {'User-agent': 'DS6001'})\n",
    "for post in reddit.json()['data']['children'][0:25]:\n",
    "    # I only want the columns in columns\n",
    "    post = {k: post['data'][k] for k in columns}\n",
    "    # add the post to the DataFrame using pd.concat() method to add a new row\n",
    "    df_reddit = pd.concat([df_reddit, pd.DataFrame(post, index=[0])], ignore_index=True)\n",
    "\n",
    "df_reddit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "The NBA has saved data on all 30 teams' shooting statistics for the 2014-2015 season here:\n",
    "https://stats.nba.com/js/data/sportvu/2015/shootingTeamData.json. Take a moment and look at\n",
    "this JSON file in your web browser. The structure of this particular JSON is complicated, but see\n",
    "if you can find the team-by-team data. In this problem our goal is to use\n",
    "pd.json_normalize() to get the data into a dataframe. The following questions will guide\n",
    "you towards this goal.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a\n",
    "Download the raw text of the NBA JSON file and register it as JSON formatted data in Python's\n",
    "memory. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file from https://stats.nba.com/js/data/sportvu/2015/shootingTeamData.json\n",
    "the_url = 'https://stats.nba.com/js/data/sportvu/2015/shootingTeamData.json'\n",
    "r = requests.get(the_url)\n",
    "nba_json = json.loads(r.text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "Describe, in words, the path that leads to the team-by-team data. (2 points)\n",
    "\n",
    "#### Answer:\n",
    "\n",
    "First, the easy part:\n",
    "The column names are in the resultSets[0].headers item, so we can use this as the column names in our dataframe.\n",
    "\n",
    "The values are in the resultSets[0].rowSet records - these will make up the rows in the dataframe. \n",
    "```\n",
    "nba_json['resultSets'][0]['rowSet']\n",
    "```\n",
    "will return a list of lists which is acceptable input to create a pandas Dataframe, so this is an easy way to create the dataframe we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1610612744',\n",
       "  'Golden State',\n",
       "  'Warriors',\n",
       "  'GSW',\n",
       "  '',\n",
       "  82,\n",
       "  48.7,\n",
       "  114.9,\n",
       "  14.9,\n",
       "  0.498,\n",
       "  16.7,\n",
       "  0.645,\n",
       "  33.7,\n",
       "  0.428,\n",
       "  21.5,\n",
       "  0.418,\n",
       "  11.0,\n",
       "  11.1,\n",
       "  28.3,\n",
       "  21.5,\n",
       "  0.563,\n",
       "  21.4,\n",
       "  44.8,\n",
       "  0.478,\n",
       "  21.2,\n",
       "  42.5,\n",
       "  0.497,\n",
       "  2.3,\n",
       "  6.3,\n",
       "  0.363,\n",
       "  10.8,\n",
       "  25.3,\n",
       "  0.429]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_json['resultSets'][0]['rowSet'][0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirming the count of columns is 33:  33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['TEAM_ID',\n",
       " 'TEAM_CITY',\n",
       " 'TEAM_NAME',\n",
       " 'TEAM_ABBREVIATION',\n",
       " 'TEAM_CODE',\n",
       " 'GP',\n",
       " 'MIN',\n",
       " 'PTS',\n",
       " 'PTS_DRIVE',\n",
       " 'FGP_DRIVE',\n",
       " 'PTS_CLOSE',\n",
       " 'FGP_CLOSE',\n",
       " 'PTS_CATCH_SHOOT',\n",
       " 'FGP_CATCH_SHOOT',\n",
       " 'PTS_PULL_UP',\n",
       " 'FGP_PULL_UP',\n",
       " 'FGA_DRIVE',\n",
       " 'FGA_CLOSE',\n",
       " 'FGA_CATCH_SHOOT',\n",
       " 'FGA_PULL_UP',\n",
       " 'EFG_PCT',\n",
       " 'CFGM',\n",
       " 'CFGA',\n",
       " 'CFGP',\n",
       " 'UFGM',\n",
       " 'UFGA',\n",
       " 'UFGP',\n",
       " 'CFG3M',\n",
       " 'CFG3A',\n",
       " 'CFG3P',\n",
       " 'UFG3M',\n",
       " 'UFG3A',\n",
       " 'UFG3P']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Confirming the count of columns is 33: \", len(nba_json['resultSets'][0]['headers']))\n",
    "nba_json['resultSets'][0]['headers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirm the count of teams is 30:  30\n"
     ]
    }
   ],
   "source": [
    "# get the count of resultSets[0].rowSet in the data, confirm the count is 30\n",
    "print(\"Confirm the count of teams is 30: \", len(nba_json['resultSets'][0]['rowSet']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c\n",
    "Use the pd.json_normalize() function to pull the team-by-team data into a dataframe.\n",
    "This is going to be tricky. You will need to use indexing on the JSON data as well as the\n",
    "record_path parameter.\n",
    "\n",
    "If you are successful, you will have a dataframe with 30 rows and 33 columns. The first row will\n",
    "refer to the Golden State Warriors, the second row will refer to the San Antonio Spurs, and the\n",
    "third row will refer to the Cleveland Cavaliers. The columns will only be named 0, 1, 2, ... at this\n",
    "point. (4 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612744</td>\n",
       "      <td>Golden State</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>GSW</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>48.7</td>\n",
       "      <td>114.9</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.498</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.645</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.428</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.418</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>28.3</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.563</td>\n",
       "      <td>21.4</td>\n",
       "      <td>44.8</td>\n",
       "      <td>0.478</td>\n",
       "      <td>21.2</td>\n",
       "      <td>42.5</td>\n",
       "      <td>0.497</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.363</td>\n",
       "      <td>10.8</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612759</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>Spurs</td>\n",
       "      <td>SAS</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>48.3</td>\n",
       "      <td>103.5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.481</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.611</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0.419</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.398</td>\n",
       "      <td>11.8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>25.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.526</td>\n",
       "      <td>21.8</td>\n",
       "      <td>43.1</td>\n",
       "      <td>0.506</td>\n",
       "      <td>18.3</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.341</td>\n",
       "      <td>6.1</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612739</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Cavaliers</td>\n",
       "      <td>CLE</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>48.7</td>\n",
       "      <td>104.3</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.481</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.622</td>\n",
       "      <td>28.2</td>\n",
       "      <td>0.394</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.360</td>\n",
       "      <td>13.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>25.2</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.524</td>\n",
       "      <td>20.5</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.473</td>\n",
       "      <td>18.2</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.447</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.299</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612746</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Clippers</td>\n",
       "      <td>LAC</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>48.6</td>\n",
       "      <td>104.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.497</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0.712</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.404</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0.385</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>27.7</td>\n",
       "      <td>0.524</td>\n",
       "      <td>19.4</td>\n",
       "      <td>40.5</td>\n",
       "      <td>0.480</td>\n",
       "      <td>18.9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.334</td>\n",
       "      <td>7.7</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612760</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>Thunder</td>\n",
       "      <td>OKC</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>48.6</td>\n",
       "      <td>110.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.480</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.677</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.402</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.390</td>\n",
       "      <td>11.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>23.7</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.524</td>\n",
       "      <td>23.7</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.497</td>\n",
       "      <td>17.5</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.451</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.321</td>\n",
       "      <td>6.6</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0              1          2    3  4   5     6      7     8      9   \\\n",
       "0  1610612744   Golden State   Warriors  GSW     82  48.7  114.9  14.9  0.498   \n",
       "1  1610612759    San Antonio      Spurs  SAS     82  48.3  103.5  14.8  0.481   \n",
       "2  1610612739      Cleveland  Cavaliers  CLE     82  48.7  104.3  16.9  0.481   \n",
       "3  1610612746    Los Angeles   Clippers  LAC     82  48.6  104.5  15.0  0.497   \n",
       "4  1610612760  Oklahoma City    Thunder  OKC     82  48.6  110.2  16.1  0.480   \n",
       "\n",
       "     10     11    12     13    14     15    16    17    18    19     20    21  \\\n",
       "0  16.7  0.645  33.7  0.428  21.5  0.418  11.0  11.1  28.3  21.5  0.563  21.4   \n",
       "1  17.8  0.611  27.1  0.419  18.0  0.398  11.8  12.2  25.3  21.4  0.526  21.8   \n",
       "2  14.3  0.622  28.2  0.394  18.6  0.360  13.4   9.7  25.2  22.7  0.524  20.5   \n",
       "3  12.7  0.712  26.5  0.404  23.9  0.385  10.9   7.8  24.3  27.7  0.524  19.4   \n",
       "4  15.3  0.677  24.7  0.402  20.6  0.390  11.9   9.5  23.7  23.3  0.524  23.7   \n",
       "\n",
       "     22     23    24    25     26   27   28     29    30    31     32  \n",
       "0  44.8  0.478  21.2  42.5  0.497  2.3  6.3  0.363  10.8  25.3  0.429  \n",
       "1  43.1  0.506  18.3  39.8  0.460  0.9  2.6  0.341   6.1  15.9  0.381  \n",
       "2  43.3  0.473  18.2  40.7  0.447  1.7  5.7  0.299   9.0  23.9  0.378  \n",
       "3  40.5  0.480  18.9  42.0  0.450  2.0  6.0  0.334   7.7  20.8  0.373  \n",
       "4  47.7  0.497  17.5  38.7  0.451  1.6  5.1  0.321   6.6  18.6  0.356  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the json into a dataframe\n",
    "# Dataframes accept a list of lists, a list of dictionaries, or a dictionary of lists\n",
    "\n",
    "# this is a different way to create the DataFrame, but not the requested way in the lab\n",
    "#df_nba = pd.DataFrame(nba_json['resultSets'][0]['rowSet'], columns=nba_json['resultSets'][0]['headers'])\n",
    "\n",
    "# this is the requested way to create the DataFrame\n",
    "df_nba = pd.json_normalize(nba_json, record_path=['resultSets','rowSet'])\n",
    "print(df_nba.shape)\n",
    "df_nba.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part d\n",
    "Find the path that leads to the headers (the column names), and extract these names as a list.\n",
    "Then set the .columns attribute of the dataframe you created in part c equal to this list. The\n",
    "result should be that the dataframe now has the correct column names. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_CITY</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_CODE</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PTS_DRIVE</th>\n",
       "      <th>FGP_DRIVE</th>\n",
       "      <th>PTS_CLOSE</th>\n",
       "      <th>FGP_CLOSE</th>\n",
       "      <th>PTS_CATCH_SHOOT</th>\n",
       "      <th>FGP_CATCH_SHOOT</th>\n",
       "      <th>PTS_PULL_UP</th>\n",
       "      <th>FGP_PULL_UP</th>\n",
       "      <th>FGA_DRIVE</th>\n",
       "      <th>FGA_CLOSE</th>\n",
       "      <th>FGA_CATCH_SHOOT</th>\n",
       "      <th>FGA_PULL_UP</th>\n",
       "      <th>EFG_PCT</th>\n",
       "      <th>CFGM</th>\n",
       "      <th>CFGA</th>\n",
       "      <th>CFGP</th>\n",
       "      <th>UFGM</th>\n",
       "      <th>UFGA</th>\n",
       "      <th>UFGP</th>\n",
       "      <th>CFG3M</th>\n",
       "      <th>CFG3A</th>\n",
       "      <th>CFG3P</th>\n",
       "      <th>UFG3M</th>\n",
       "      <th>UFG3A</th>\n",
       "      <th>UFG3P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612744</td>\n",
       "      <td>Golden State</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>GSW</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>48.7</td>\n",
       "      <td>114.9</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.498</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.645</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.428</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.418</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>28.3</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.563</td>\n",
       "      <td>21.4</td>\n",
       "      <td>44.8</td>\n",
       "      <td>0.478</td>\n",
       "      <td>21.2</td>\n",
       "      <td>42.5</td>\n",
       "      <td>0.497</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.363</td>\n",
       "      <td>10.8</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612759</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>Spurs</td>\n",
       "      <td>SAS</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>48.3</td>\n",
       "      <td>103.5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.481</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.611</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0.419</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.398</td>\n",
       "      <td>11.8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>25.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.526</td>\n",
       "      <td>21.8</td>\n",
       "      <td>43.1</td>\n",
       "      <td>0.506</td>\n",
       "      <td>18.3</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.341</td>\n",
       "      <td>6.1</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612739</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Cavaliers</td>\n",
       "      <td>CLE</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>48.7</td>\n",
       "      <td>104.3</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.481</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.622</td>\n",
       "      <td>28.2</td>\n",
       "      <td>0.394</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.360</td>\n",
       "      <td>13.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>25.2</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.524</td>\n",
       "      <td>20.5</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.473</td>\n",
       "      <td>18.2</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.447</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.299</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612746</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Clippers</td>\n",
       "      <td>LAC</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>48.6</td>\n",
       "      <td>104.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.497</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0.712</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.404</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0.385</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>27.7</td>\n",
       "      <td>0.524</td>\n",
       "      <td>19.4</td>\n",
       "      <td>40.5</td>\n",
       "      <td>0.480</td>\n",
       "      <td>18.9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.334</td>\n",
       "      <td>7.7</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612760</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>Thunder</td>\n",
       "      <td>OKC</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>48.6</td>\n",
       "      <td>110.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.480</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.677</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.402</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.390</td>\n",
       "      <td>11.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>23.7</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.524</td>\n",
       "      <td>23.7</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.497</td>\n",
       "      <td>17.5</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.451</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.321</td>\n",
       "      <td>6.6</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TEAM_ID      TEAM_CITY  TEAM_NAME TEAM_ABBREVIATION TEAM_CODE  GP   MIN  \\\n",
       "0  1610612744   Golden State   Warriors               GSW            82  48.7   \n",
       "1  1610612759    San Antonio      Spurs               SAS            82  48.3   \n",
       "2  1610612739      Cleveland  Cavaliers               CLE            82  48.7   \n",
       "3  1610612746    Los Angeles   Clippers               LAC            82  48.6   \n",
       "4  1610612760  Oklahoma City    Thunder               OKC            82  48.6   \n",
       "\n",
       "     PTS  PTS_DRIVE  FGP_DRIVE  PTS_CLOSE  FGP_CLOSE  PTS_CATCH_SHOOT  \\\n",
       "0  114.9       14.9      0.498       16.7      0.645             33.7   \n",
       "1  103.5       14.8      0.481       17.8      0.611             27.1   \n",
       "2  104.3       16.9      0.481       14.3      0.622             28.2   \n",
       "3  104.5       15.0      0.497       12.7      0.712             26.5   \n",
       "4  110.2       16.1      0.480       15.3      0.677             24.7   \n",
       "\n",
       "   FGP_CATCH_SHOOT  PTS_PULL_UP  FGP_PULL_UP  FGA_DRIVE  FGA_CLOSE  \\\n",
       "0            0.428         21.5        0.418       11.0       11.1   \n",
       "1            0.419         18.0        0.398       11.8       12.2   \n",
       "2            0.394         18.6        0.360       13.4        9.7   \n",
       "3            0.404         23.9        0.385       10.9        7.8   \n",
       "4            0.402         20.6        0.390       11.9        9.5   \n",
       "\n",
       "   FGA_CATCH_SHOOT  FGA_PULL_UP  EFG_PCT  CFGM  CFGA   CFGP  UFGM  UFGA  \\\n",
       "0             28.3         21.5    0.563  21.4  44.8  0.478  21.2  42.5   \n",
       "1             25.3         21.4    0.526  21.8  43.1  0.506  18.3  39.8   \n",
       "2             25.2         22.7    0.524  20.5  43.3  0.473  18.2  40.7   \n",
       "3             24.3         27.7    0.524  19.4  40.5  0.480  18.9  42.0   \n",
       "4             23.7         23.3    0.524  23.7  47.7  0.497  17.5  38.7   \n",
       "\n",
       "    UFGP  CFG3M  CFG3A  CFG3P  UFG3M  UFG3A  UFG3P  \n",
       "0  0.497    2.3    6.3  0.363   10.8   25.3  0.429  \n",
       "1  0.460    0.9    2.6  0.341    6.1   15.9  0.381  \n",
       "2  0.447    1.7    5.7  0.299    9.0   23.9  0.378  \n",
       "3  0.450    2.0    6.0  0.334    7.7   20.8  0.373  \n",
       "4  0.451    1.6    5.1  0.321    6.6   18.6  0.356  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the column names\n",
    "df_nba.columns = nba_json['resultSets'][0]['headers']\n",
    "df_nba.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "Save the NBA dataframe you extracted in problem 4 as a JSON-formatted text file on your local\n",
    "machine. Format the JSON so that it is organized as dictionary with three lists: columns lists\n",
    "the column names, index lists the row names, and data is a list-of-lists of data points, one\n",
    "list for each row. (Hint: this is possible with one line of code) (2 points)\n",
    "\n",
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dianam\\\\Documents\\\\jlab_datascience\\\\PlayGround\\\\UVa\\\\ds6001\\\\mod3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the orient == split seems to create the requested format described in the problem 5 description.\n",
    "# the possible orient options are split, records, index, and table.\n",
    "df_nba.to_json('nba_shooting.json', orient='split', indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the saved images:\n",
    "\n",
    "|----|----|\n",
    "|<img src='file_tree.JPG' />|<img src='nba_saved_format.JPG' />|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds6001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d737332527f4dec375ac76e00465760aa90717cb1ff23bf26e747a315a010455"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
